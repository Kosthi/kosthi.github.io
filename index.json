[{"categories":["LLM"],"content":"1 作业概述 本次作业中，你将亲自动手实践提升单 GPU 训练速度和将训练扩展到多 GPU 的方法。 ","date":"2026-01-31","objectID":"/cs336-assign2/:1:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"需实现的内容 基准测试与性能分析工具 FlashAttention-2 的 Triton 内核 分布式数据并行训练 优化器状态分片 作业地址： Assignment2-systems GitHub仓库 接下来我将分享完成作业的一部分细节和心得。 ","date":"2026-01-31","objectID":"/cs336-assign2/:1:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2 性能分析与基准测试 ","date":"2026-01-31","objectID":"/cs336-assign2/:2:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2.1 动机 在进行任何优化之前，先对程序进行性能分析是很有必要的，这能帮我们明确资源（如时间和内存）的消耗重点。否则，我们可能会在对整体性能影响不大的模块上浪费精力，无法带来显著的端到端性能提升。 我们将实现三种性能评估方案： (a) 基于 Python 标准库的简单端到端基准测试，用于统计前向和反向传播耗时； (b) 使用 NVIDIA Nsight Systems 工具分析计算过程，明确 CPU 和 GPU 上各操作的耗时分布； (c) 内存使用情况分析。 ","date":"2026-01-31","objectID":"/cs336-assign2/:2:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2.2 模型规格 在本次作业中，我们将对不同规格的模型进行基准测试和性能分析，以观察模型规模对性能的影响。所有模型的词汇量均设为 10000，批次大小设为 4，仅调整上下文长度。 不同模型规格参数如下： 模型规模 模型维度 $d_{model}$ 前馈网络维度 $d_{ff}$ 层数 $num_layers$ 注意力头数 $num_heads$ small 768 3072 12 12 medium 1024 4096 24 16 large 1280 5120 36 20 xl 1600 6400 48 25 2.7B 2560 10240 32 32 ","date":"2026-01-31","objectID":"/cs336-assign2/:2:2","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2.3 端到端基准测试 首先，我们对模型进行最基础的性能分析 —— 统计前向和反向传播的耗时。由于我们只关注速度和内存，实验中可以使用随机初始化的权重和数据。 对于 GPU 代码进行基准测试时，需注意 CUDA 调用是异步的：调用内核后 CPU 会立即继续执行，因此直接测量函数返回时间无法反映 GPU 实际计算耗时。为了准确测量内核运行时间，应在测试前后调用 torch.cuda.synchronize() 以确保 GPU 操作完成。这是构建可靠性能分析工具的基础。 ","date":"2026-01-31","objectID":"/cs336-assign2/:2:3","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"作业题（benchmarking_script）：4 分 (a) 编写一个脚本，对模型的前向和反向传播进行基础的端到端基准测试。具体来说，你的脚本需要支持以下功能： 根据给定的超参数（如层数）初始化模型； 生成随机批次的测试数据； 先执行 w 次预热步骤（不计入正式计时），然后统计 n 次迭代的耗时（可通过参数控制仅测试前向传播，或同时测试前向和反向传播）； 计时工具可使用 Python 的 timeit 模块（例如 timeit 函数，或 timeit.default_timer()——该函数调用系统最高精度的时钟，比 time.time() 更适合基准测试）； 每次迭代后调用 torch.cuda.synchronize()。 提交要求：一个脚本，能够根据给定超参数初始化基础 Transformer 模型，生成随机批次数据，并统计前向和反向传播的耗时。 答案：benchmarking_script.py (b) 针对 1.1.2 节中描述的所有模型规格，统计其前向和反向传播的耗时。预热步骤设为 5 次，正式测试迭代 10 次，计算耗时的平均值和标准差。前向传播耗时多少？反向传播呢？测试结果的波动性大吗？标准差是否较小？ 提交要求：1-2 句话，简要说明你的测试结果。 答案：前向与反向传播耗时随模型规格增大而显著增加（反向耗时约为前向的 1.8 倍）。测试结果中，仅 large 模型在前向传播阶段表现出异常高的波动（标准差约 15.6ms），其余所有模型标准差均低于 1ms，整体稳定性极高。 Model Total Mean (ms) Total Std (ms) Forward Mean (ms) Forward Std (ms) Backward Mean (ms) Backward Std (ms) small 57.199 0.36 20.577 0.114 36.623 0.296 medium 150.074 0.305 50.899 0.191 99.175 0.24 large 343.988 15.576 121.522 15.565 222.466 0.487 xl 647.669 0.492 226.776 0.134 420.893 0.46 2.7B 931.531 0.788 334.754 0.25 596.778 0.563 (c) 基准测试的一个常见误区是不执行预热步骤。请重复上述实验，但不进行预热，观察这会对结果产生什么影响？你认为原因是什么？另外，尝试将预热步骤设为 1 或 2 次，结果为何仍然会有差异？ 提交要求：2-3 句话，回答上述问题。 答案：不执行预热会导致平均耗时显著增加且方差极大，这是因为测试数据包含了 CUDA 上下文初始化、显存分配及内核编译 等高昂的一次性开销。仅进行 1-2 次预热结果仍有差异，是因为 GPU 往往需要更多迭代才能 将时钟频率提升至高性能状态（Clock Boost） 并使硬件调度达到稳态，短期预热不足以完全消除这种硬件延迟。 未执行预热结果： Model Total Mean (ms) Total Std (ms) Forward Mean (ms) Forward Std (ms) Backward Mean (ms) Backward Std (ms) small 108.639 162.533 61.526 129.748 47.114 32.788 medium 205.943 168.338 91.845 126.576 114.097 41.762 large 403.33 183.065 164.772 146.419 238.558 36.71 xl 717.864 219.592 282.802 175.108 435.062 44.488 2.7B 984.532 165.056 377.542 134.342 606.99 30.722 预热 2 次后结果： Model Total Mean (ms) Total Std (ms) Forward Mean (ms) Forward Std (ms) Backward Mean (ms) Backward Std (ms) small 57.415 0.589 20.679 0.514 36.735 0.354 medium 152.697 0.249 51.815 0.108 100.882 0.222 large 346.826 16.261 122.62 16.389 224.206 1.992 xl 647.414 0.774 226.728 0.106 420.685 0.695 2.7B 932.151 0.744 334.898 0.105 597.253 0.738 ","date":"2026-01-31","objectID":"/cs336-assign2/:2:4","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2.4 Nsight Systems 性能分析工具 ","date":"2026-01-31","objectID":"/cs336-assign2/:2:5","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业二：系统与并行计算","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"1 作业概述 本次作业中，你将获得训练语言模型解决数学问题时进行推理的实践经验。 ","date":"2026-01-13","objectID":"/cs336-assign5/:1:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"需实现的内容 针对 Hendrycks 等人 [2021] 提出的竞赛数学问题数据集 MATH，实现零样本提示基线模型。 利用更强推理模型（DeepSeek R1，DeepSeekAI 等人，2025）的推理轨迹进行有监督微调（SFT）。 采用专家迭代（Expert Iteration）方法，通过验证奖励提升推理性能。 采用组相对策略优化（GRPO）方法，通过验证奖励提升推理性能。 对于感兴趣的同学，我们将在未来几天发布可选作业部分：使语言模型与人类偏好对齐。 ","date":"2026-01-13","objectID":"/cs336-assign5/:1:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"需运行的内容 评估 Qwen 2.5 Math 1.5B 模型的零样本提示性能（作为基线）。 利用 R1 的推理轨迹对 Qwen 2.5 Math 1.5B 进行有监督微调（SFT）。 利用验证奖励对 Qwen 2.5 Math 1.5B 进行专家迭代训练。 利用验证奖励对 Qwen 2.5 Math 1.5B 进行 GRPO 训练。 作业地址： Assignment5-alignment GitHub仓库 接下来我将分享完成作业的一部分细节和心得。 ","date":"2026-01-13","objectID":"/cs336-assign5/:1:2","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"2 语言模型的推理能力 ","date":"2026-01-13","objectID":"/cs336-assign5/:2:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"2.1 动机 语言模型的显著应用场景之一是构建能处理多种自然语言处理任务的通用系统。本次作业将聚焦语言模型的一个新兴应用场景：数学推理。我们将以此为测试平台，搭建评估体系、执行有监督微调，并探索利用强化学习（RL）训练语言模型进行推理的方法。 本次作业与以往作业有两处不同： 不再使用之前作业中的语言模型代码库和模型。理想情况下，我们希望使用之前作业中训练的基础语言模型，但微调这些模型无法获得令人满意的结果 —— 它们的能力太弱，无法展现复杂的数学推理能力。因此，我们将切换到一个可访问的现代高性能语言模型（Qwen 2.5 Math 1.5B Base），并在此基础上开展大部分工作。 引入新的基准数据集评估语言模型。此前，我们认为交叉熵可作为许多下游任务的良好替代指标。但本次作业的核心是缩小基础模型与下游任务之间的差距，因此必须使用独立于交叉熵的评估方法。我们将采用 Hendrycks 等人 [2021] 提出的 MATH 12K 数据集，该数据集包含具有挑战性的高中竞赛数学问题。我们将通过对比模型输出与参考答案来评估语言模型的性能。 ","date":"2026-01-13","objectID":"/cs336-assign5/:2:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"2.2 思维链推理与推理强化学习 语言模型领域近期的一个热门趋势是利用思维链（Chain-of-Thought）推理提升各类任务的性能。思维链指的是逐步推理问题的过程，在得出最终答案前生成中间推理步骤。 语言模型的思维链推理 早期的思维链方法通过 “草稿本”（scratchpad）将问题分解为中间步骤，微调语言模型解决算术等简单数学任务 [Nye 等人，2021]。其他研究则通过提示强模型在回答前 “逐步思考”，发现这能显著提升其在小学算术题等数学推理任务上的性能 [Wei 等人，2023]。 基于专家迭代的推理学习 自训练推理器（STaR）[Zelikman 等人，2022] 将推理构建为一个自举循环：预训练模型首先生成多样化的思维链（CoT），仅保留能得出正确答案的思维链，然后利用这些 “专家” 轨迹进行微调。重复该循环可提升语言模型的推理能力和解题率。STaR 证明，这种基于专家迭代 [Anthony 等人，2017] 的方法，通过对生成答案进行自动字符串匹配验证，无需人工编写推理轨迹即可自举推理能力。 基于验证奖励的推理强化学习（o1、R1） 近期研究探索了使用更强大的强化学习算法结合验证奖励来提升推理性能。OpenAI 的 o1（及后续的 o3/o4）[OpenAI 等人，2024]、DeepSeek 的 R1 [DeepSeek-AI 等人，2025] 以及 Moonshot 的 kimi k1.5 [Team 等人，2025] 均采用策略梯度方法 [Sutton 等人，1999] 在数学和代码任务上进行训练，通过字符串匹配或单元测试验证答案正确性，在竞赛数学和编程任务上取得了显著性能提升。后续研究如 Open-R1 [Face，2025]、SimpleRL-Zoo [Zeng 等人，2025] 和 TinyZero [Pan 等人，2025] 证实，即使在参数规模仅为 1.5B 的模型上，基于验证奖励的纯强化学习也能提升推理性能。 实验设置：模型与数据集 在后续章节中，我们将逐步采用更复杂的方法训练基础语言模型，使其能通过逐步推理解决数学问题。本次作业将使用 Qwen 2.5 Math 1.5B Base 模型，该模型基于 Qwen 2.5 1.5B 模型，在高质量合成数学预训练数据上进行了持续预训练 [Yang 等人，2024]。MATH 数据集可在 Together 集群的 /data/a5-alignment/MATH 路径下获取。 开源替代数据集（面向开源审计者） 由于版权限制，MATH 数据集未公开。若你在本地完成作业，可使用以下开源数学推理数据集： Countdown [Pan 等人，2025]：基于英国电视节目《Countdown》的简单合成任务，是小规模推理强化学习的常用测试平台，获取链接：[此处]。 GSM8K [Cobbe 等人，2021a]：小学算术题数据集，难度低于 MATH，适合调试代码正确性并熟悉推理强化学习流程，获取链接：[此处]。 Tulu 3 SFT Math [Lambert 等人，2025]：使用 GPT-4o 和 Claude 3.5 Sonnet 生成的合成数学问题，由于是合成数据，部分答案（甚至问题）可能存在错误，获取链接：[此处]。 其他数学 SFT 数据集：[此处链接]。 若数据集中未直接提供简短真实标签（如 1/2），可使用 Math-Verify 等数学答案解析器处理真实标签列。 ","date":"2026-01-13","objectID":"/cs336-assign5/:2:2","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"3 评估零样本 MATH 性能 我们首先评估基础语言模型在 MATH 数据集的 5K 测试集上的性能。建立该基线有助于理解后续每种方法对模型行为的影响。 ","date":"2026-01-13","objectID":"/cs336-assign5/:3:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"作业题（数学基线性能）：4 分 (a) 编写脚本评估 Qwen 2.5 Math 1.5B 模型在 MATH 数据集上的零样本性能 该脚本需要完成以下任务： 从 /data/a5-alignment/MATH/validation.jsonl 加载 MATH 验证集样本； 使用 r1_zero 提示词将这些样本格式化为语言模型可接收的字符串提示词； 为每个样本生成模型输出； 计算评估指标； 将样本、模型生成结果以及对应的评估分数序列化保存到磁盘，以便后续作业题进行分析。 在实现过程中，编写一个如下所示的 evaluate_vllm 方法会很有帮助，后续你可以复用该方法： def evaluate_vllm( vllm_model: LLM, reward_fn: Callable[[str, str], dict[str, float]], prompts: List[str], eval_sampling_params: SamplingParams ) -\u003e None: \"\"\" 针对一组提示词评估语言模型性能， 计算评估指标，并将结果序列化保存到磁盘。 \"\"\"提交要求：一份用于评估零样本 MATH 数据集基线性能的脚本。 See at [eval.py][https://github.com/Kosthi/assignment5-alignment/blob/main/eval.py] (b) 在 Qwen 2.5 Math 1.5B 模型上运行你的评估脚本 统计模型生成结果分别落入以下三类的数量： 格式奖励和答案奖励均为 1（完全正确）； 格式奖励为 1、答案奖励为 0（格式正确，答案错误）； 格式奖励和答案奖励均为 0（格式和答案均错误）。 观察至少 10 个格式奖励为 0 的案例，你认为问题出在基础模型的输出上，还是出在解析器上？为什么？再观察至少 10 个格式奖励为 1 但答案奖励为 0 的案例，你有什么看法？ 提交要求：关于模型和奖励函数性能的分析说明，包含各类案例的示例。 1. 数量统计 根据日志开头的汇总信息（num_examples=5000）及各类计数，模型生成结果分布如下： 格式奖励和答案奖励均为 1（完全正确）：count(fmt=1,ans=1)=139 例。 格式奖励为 1、答案奖励为 0（格式正确，答案错误）：count(fmt=1,ans=0)=693 例。 格式奖励和答案奖励均为 0（格式和答案均错误）：count(fmt=0,ans=0)=4168 例。 2. 对“格式奖励为 0”案例的观察 在日志提供的至少10个此类案例中（标记为 sample_fmt0_ans0_examples=10），问题主要出在基础模型的输出上，而非解析器。 主要原因：这些失败案例的共同点是模型没有遵循指定的输出格式。根据日志，正确的格式应包含清晰的 \u003cthink\u003e 推理过程和用 \u003canswer\u003e 标签包裹的最终答案。然而，问题模型输出经常出现： 格式结构混乱：例如在回答 “What is the positive difference between $120%$ of 30 and $130%$ of 20?” 时，模型在 \u003cthink\u003e 标签内直接给出了答案，并且混入了 \u003cend think\u003e \u003canswer\u003e 等未定义的标签，导致解析失败。 输出无关内容与符号：例如在回答函数逆问题 “Let $f(x)=7x+5$…” 时，模型的 \u003cthink\u003e 内容包含大量无关代码片段、乱码字符（如 “\u003c/\u003cbr\u003e下一格*/{ */”），甚至插入图片链接，完全偏离了数学推理。 推理与答案未分离：模型经常在思考部分就写下“答案是…”，或者最终答案没有用要求的标签包裹。 这些现象表明，基础模型在遵循严格的结构化输出指令上存在困难，未能生成可供解析器正确处理的文本。 3. 对“格式奖励为 1 但答案奖励为 0”案例的观察 在日志随后提供的至少10个此类案例中（标记为 sample_fmt1_ans0_examples=10），模型成功遵循了格式要求，但答案本身是错误的。 主要看法：这揭示了模型的核心能力局限。在格式正确的情况下，错误类型包括： 数学计算错误：例如计算 $i^5+i^{-25}+i^{45}$ 时，模型得出 $2i$，但正确答案应为 $i$。 逻辑推理错误：例如在求满足不等式 $|x|+1\u003e7$ 和 $|x+1|\\le7$ 的整数和时，模型正确列出了计算步骤，但错误地将 -6 包含在内，得到和 -21，正确答案应为 -15。 最终答案表述不精确：例如问垂直线条数量，模型在 \u003canswer\u003e 中正确给出了导致分母为零的值 “-3$ and $2$”，却没有将其转化为最终答案“2条”。 这表明，模型在一定程度上学会了“模仿”解题的格式和框架，但其数学推理、计算准确性和对问题最终要求的理解仍然不足。 (c) Qwen 2.5 Math 1.5B 模型在 MATH 数据集上的零样本基线性能表现如何？ 提交要求：用 1-2 句话概括评估指标结果。 根据评估日志中的指标（mean_reward=0.0278，且完全正确的比例仅为139/5000≈2.78%），该模型在MATH数据集上的零样本基线性能非常弱，其生成结果在格式和答案上的整体正确率极低，尚不具备可靠解决复杂数学问题的能力。 ","date":"2026-01-13","objectID":"/cs336-assign5/:3:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"4 用于MATH的有监督微调 ","date":"2026-01-13","objectID":"/cs336-assign5/:4:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"问题(sft_experiment)：在MATH数据集上运行SFT（2分）（2个H100小时） 1. 使用Qwen 2.5 Math 1.5B基础模型，在推理SFT示例（在/data/a5-alignment/MATH/sft.jsonl中提供）上运行SFT，改变SFT中唯一示例的数量，范围为{128, 256, 512, 1024}，以及使用完整数据集。调整学习率和批次大小，以在使用完整数据集时至少达到15%的验证准确率。 提交内容： 与不同数据集大小相关的验证准确率曲线。 少量sft的样本反而比大量的更好, 熵也下降的更快更低, 样本多了模型反而 confuse。 2. 过滤推理SFT示例，仅包括产生正确答案的示例。在（完整）过滤数据集上运行SFT，并报告过滤数据集的大小和你达到的验证准确率。 提交内容： 报告数据集的大小和你达到的验证准确率曲线。将你的发现与之前的SFT实验进行比较。 实验暂定 ","date":"2026-01-13","objectID":"/cs336-assign5/:4:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"5 用于MATH的专家迭代 ","date":"2026-01-13","objectID":"/cs336-assign5/:5:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"问题(expert_iteration_experiment)：在MATH数据集上运行专家迭代（2分）（6个H100小时） 在MATH数据集（在/data/a5-alignment/MATH/train.jsonl中提供）上使用Qwen 2.5 Math 1.5B Base模型运行专家迭代，改变每个问题的rollout数量G和SFT步骤中使用的轮数，并使用n_ei_steps = 5。改变每个专家迭代步骤的批次大小（即Db的大小）在{512, 1024, 2048}中。（你不需要尝试这些超参数的所有可能组合。只要足够得出关于每个的结论即可。）记录训练过程中模型响应的熵。确保vLLM在第二个答案标签处终止生成，如SFT部分所做的那样。 提交内容： 与不同rollout配置相关的验证准确率曲线。至少尝试2种不同的rollout计数和轮数计数。 一个在MATH上达到至少15%验证准确率的模型。 一个简短的2句讨论，将你的性能与SFT性能进行比较，以及在EI步骤之间的性能比较。 一个显示训练过程中模型响应熵的图表。 实验暂定 ","date":"2026-01-13","objectID":"/cs336-assign5/:5:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"6 策略梯度入门 ","date":"2026-01-13","objectID":"/cs336-assign5/:6:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign5/"},{"categories":["LLM"],"content":"为什么系统爱好者都应该学习大模型？ 在当今 AI 技术浪潮中，掌握大模型知识已成为系统开发者的必备技能。通过参与斯坦福 CS336 大模型系统课程，开始从零构建大模型的实践之旅。这门课程很可能在未来 3 年内成为系统领域的标杆课程（正如 CMU 15-445 数据库课程近年来的地位）。 ","date":"2025-06-14","objectID":"/cs336-assign1/:1:0","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"作业概览 本次作业通过以下三个模块实现了一个小型语言模型： Tokenizer 设计与实现 — 字节对编码（BPE）分词器 模型架构编码 — 含 Self-Attention 机制的 Transformer 优化器开发 — AdamW 优化器 作业地址：Assignment1-Basics GitHub 仓库 接下来，我将分享完成作业的一部分细节和心得。 ","date":"2025-06-14","objectID":"/cs336-assign1/:1:1","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"一、字节对编码（BPE）分词器 ","date":"2025-06-14","objectID":"/cs336-assign1/:2:0","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"1.1 Unicode 标准 **Problem（unicode1）：理解 Unicode（1 分） (a) chr(0)返回什么 Unicode 字符？ NULL字符，即ASCII空字符 \u003e\u003e\u003e chr(0) '\\x00'(b) 该字符的字符串表示（__repr__()）与其打印表示有何不同？ repr()函数显示转移序列’\\\\x00’，打印什么都不显示，即空字符 \u003e\u003e\u003e repr(chr(0)) \"'\\\\x00'\" \u003e\u003e\u003e print(chr(0))(c) 该字符出现在文本中时会发生什么？可在 Python 解释器中尝试以下代码验证 空字符虽然在打印时不可见，但仍作为 Python 字符串的一部分，这表明 Python 字符串可以包含不可见的字符，且这些空字符仍然会影响字符串的存储和处理。 \u003e\u003e\u003e chr(0) '\\x00' \u003e\u003e\u003e print(chr(0)) \u003e\u003e\u003e \"this is a test\" + chr(0) + \"string\" 'this is a test\\x00string' \u003e\u003e\u003e print(\"this is a test\" + chr(0) + \"string\") this is a teststring","date":"2025-06-14","objectID":"/cs336-assign1/:2:1","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"1.2 Unicode 编码 Problem（unicode2）：Unicode 编码（1 分） (a) 为什么优先选择在 UTF-8 编码的字节上训练分词器，而非 UTF-16 或 UTF-32？可对比不同编码对各类输入字符串的输出结果。 训练分词器时处理的是字节序列，UTF-8能更紧凑地表示常见字符，减少序列长度，这对模型训练更高效。而且UTF-8向后兼容ASCII，处理英文文本时特别高效。 \u003e\u003e\u003e test_string=\"你好,世界!\" \u003e\u003e\u003e list(test_string.encode(\"utf-8\")) [228, 189, 160, 229, 165, 189, 44, 228, 184, 150, 231, 149, 140, 33] \u003e\u003e\u003e list(test_string.encode(\"utf-16\")) [255, 254, 96, 79, 125, 89, 44, 0, 22, 78, 76, 117, 33, 0] \u003e\u003e\u003e list(test_string.encode(\"utf-32\")) [255, 254, 0, 0, 96, 79, 0, 0, 125, 89, 0, 0, 44, 0, 0, 0, 22, 78, 0, 0, 76, 117, 0, 0, 33, 0, 0, 0](b) 以下函数意图将 UTF-8 字节串解码为 Unicode 字符串，但存在错误。该函数为何不正确？请提供一个导致错误结果的输入字节串示例。 该函数不正确，因为它逐字节解码，这对于多字节UTF-8 字符会失败。单独的字节\\xe4是无效的 UTF-8字符，会引发UnicodeDecodeError 异常。 def decode_utf8_bytes_to_str_wrong(bytestring: bytes): return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring]) \u003e\u003e\u003e decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\")) 'hello' \u003e\u003e\u003e \"你好\".encode(\"utf-8\") b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd' \u003e\u003e\u003e decode_utf8_bytes_to_str_wrong(\"你好\".encode(\"utf-8\")) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e import platform File \"\u003cstdin\u003e\", line 2, in decode_utf8_bytes_to_str_wrong import sys UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data \u003e\u003e\u003e bytes([0xe4,0xbd,0xa0]).decode(\"utf-8\") '你' ## 汉字“你”占用了3个字节(c) 给出一个无法解码为任何 Unicode 字符的两字节序列。 b'\\x80\\x81'是无效的，因为在 UTF-8 中，任何以二进制 10 开头的字节（如 0x80）必须是延续字节，但此处它作为首字节出现，前面没有有效的前导字节。 \u003e\u003e\u003e b'\\x80\\x81'.decode(\"utf-8\") Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e import platform UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte \u003e\u003e\u003e b'\\xe4\\x80\\x81'.decode(\"utf-8\") '䀁' ## 生僻字 䀁(yòu) UTF-8编码 E4 80 81","date":"2025-06-14","objectID":"/cs336-assign1/:2:2","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"1.3 BPE 分词器训练实验 预分词前移除特殊标记 special_tokens = [\"\u003c|endoftext|\u003e\", \"\u003csep\u003e\", \"[SPECIAL]\"] # 注意先转义再用\"|\"分割，在正则表达式中\"|\"表示为或 \u003c|endoftext|\u003e|\u003csep\u003e|[SPECIAL] # \"|\".join(special_tokens) 结果 \u003c\\|endoftext\\|\u003e\\|\u003csep\u003e\\|\\[SPECIAL\\] # Wrong: re.escape(\"|\".join(special_tokens)) 结果 \u003c\\|endoftext\\|\u003e|\u003csep\u003e|\\[SPECIAL\\] # True: \"|\".join([re.escape(token) for token in special_tokens])BPE 优化策略 为了追求高性能，我使用 Pybind11 绑定 C++ 代码：预分词由 Python 处理，BPE 归并过程交给 C++。主要优化包括： 并行化处理 — 使用 OpenMP 并行统计，避免锁竞争 惰性删除队列 — 复杂度从 O(NlogN) 降至 O(KlogN) 增量更新 — 只更新受影响的相邻 pair 高效数据结构 — 整数 ID 替代字符串，自定义哈希函数 性能对比（TinyStoriesV2-GPT4-train 数据集）： 版本 BPE归并训练 提升 Python 10min++ 基准 C++ 未优化 366s ~2x C++ 优化 1.08s 300x 详细的优化原理和实现请阅读：BPE 分词器高性能优化：从 10 分钟到 1 秒的实践 Problem（train_bpe_tinystories）：在 TinyStories 上训练 BPE（2 分） (a) 训练耗时多久、占用多少内存？词汇表中最长的令牌是什么？是否合理？ 28.03s 10GB 最长的 token 是 token：\" accomplishment\"，对应的 id： 7159，长度： 15 个字符（包括前面的空格） 合理。 (b) 分析代码性能。分词器训练过程中哪个部分耗时最长？ N：去重后的单词总数（distinct words） L：平均单词长度（字符数/初始token数） V：目标词汇表大小 M：合并次数 = V - 256 - |special_tokens|（从256个字节token开始） K：特定pair的出现次数 P：临时Pair频率统计表 未优化前耗时最大是BPE归并过程，需要6分钟，时间复杂度为O(M × N × L)，空间复杂度O(N × L + P)。 优化后只要1s左右，时间复杂度为O(N × L + M)， 位置索引: O(N × L)，存储每个相邻对的位置，优先级队列：O(P)，总计空间复杂度为O(N × L + P)。优化算法需要额外的位置索引存储，但避免了每轮重新统计的开销。 优化后耗时最大为预分词过程，16进程并行30s，24进程并行25s，时间复杂度O(N*L/D)，D为进程个数。 Problem（train_bpe_expts_owt）：在 OpenWebText 上训练 BPE（2 分） (a) 在 OpenWebText 数据集上训练字节级 BPE 分词器，词汇表最大大小设为 32,000。将生成的词汇表和合并序列序列化到磁盘以便后续查看。词汇表中最长的令牌是什么？是否合理？ 最长的令牌列表 ID: 25835 | 字节长度: 64 | 内容: ‘—————————————————————-’ ID: 25821 | 字节长度: 64 | 内容: ‘ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ’ (b) 对比在 TinyStories 和 OpenWebText 上训练的分词器。 有一些 token 本身里面包含换行符 \\n ，写文件的时候没有做转义 ，所以「一条合并规则」在文件里被拆成了多行。 \\n The\\n ← 中间这个 \\n 是 token 本身，最后那个 \\n 是行结束\r（这一行是空的，因为前面那个 \\n 把光标移到下一行）\rThe","date":"2025-06-14","objectID":"/cs336-assign1/:2:3","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"1.4 分词器实验 Problem（tokenizer_experiments）：分词器实验（4 分） (a) 从 TinyStories 和 OpenWebText 中各采样 10 个文档。使用之前训练的 TinyStories 分词器（词汇表大小 10K）和 OpenWebText 分词器（词汇表大小 32K），将这些采样文档编码为整数 ID。每个分词器的压缩比（字节数 / 令牌数）是多少？ TinyStories-10K 分词器在 TinyStories 上的压缩比为 4.14 字节/令牌，OpenWebText-32K 分词器在 OpenWebText 上的压缩比为 4.70 字节/令牌。 (b) 用 TinyStories 分词器编码 OpenWebText 采样文档会发生什么？对比压缩比，或定性描述结果。 使用 TinyStories-10K 分词器编码 OpenWebText 文档时，压缩比降至 3.26 字节/令牌，表明更小的词汇表（10K）在面对复杂文本时会产生更多令牌，导致压缩效率降低。 (c) 估算分词器的吞吐量（如字节 / 秒）。编码 Pile 数据集（825GB 文本）需要多长时间？ TinyStories-10K 分词器吞吐量约 626,519.6 字节/秒，编码 825GB Pile 数据集约需 16.4 天；OpenWebText-32K 约 763,734.4 字节/秒，约需 13.4天。 (d) 使用 TinyStories 和 OpenWebText 分词器，分别将对应的训练集和开发集编码为整数令牌 ID（后续用于训练语言模型）。建议将令牌 ID 序列化为uint16类型的 NumPy 数组。为什么uint16是合适的选择？ 两个分词器的词汇表大小（10K 和 32K）均小于 65,536（2¹⁶），因此 uint16 足以表示所有令牌 ID，且比 uint32 节省 50% 存储空间。 ","date":"2025-06-14","objectID":"/cs336-assign1/:2:4","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"二、Transformer 资源核算 ","date":"2025-06-14","objectID":"/cs336-assign1/:3:0","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"2.1 FLOPs 核算基础 了解 Transformer 各组成部分的计算量和内存占用情况十分有用。我们将逐步开展基础的“浮点运算次数（FLOPs）核算”。 Transformer 的绝大多数浮点运算都来自矩阵乘法，因此核心思路很简单： 列出 Transformer 前向传播过程中所有的矩阵乘法操作 将每个矩阵乘法转换为所需的浮点运算次数 矩阵乘法 FLOPs 规则：给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和 $B \\in \\mathbb{R}^{n \\times p}$，矩阵乘法 $AB$ 需消耗 $2mnp$ 个 FLOPs。因为 $(AB)[i,j] = A[i,:] \\cdot B[:,j]$ 包含 $n$ 次加法和 $n$ 次乘法，共 $2n$ 个浮点运算；而矩阵 $AB$ 共有 $m \\times p$ 个元素，因此总 FLOPs 为 $2mnp$。 ","date":"2025-06-14","objectID":"/cs336-assign1/:3:1","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"2.2 GPT-2 XL 资源核算 Problem（transformer_accounting）：Transformer 语言模型资源核算（5 分） (a) GPT-2 XL 可训练参数计算 考虑 GPT-2 XL 模型配置： 词汇表大小（vocab_size）：50,257 上下文长度（context_length）：1,024 层数（num_layers）：48 模型维度（d_model）：1,600 注意力头数（num_heads）：25 前馈网络内层维度（d_ff）：6,400 若按此配置构建模型，该模型将包含多少个可训练参数？假设每个参数采用单精度浮点数（single-precision floating point）表示，仅加载该模型需要占用多少内存？ 1. 令牌嵌入层（Token Embedding） 作用：将整数令牌 ID 映射为 d_model 维向量，参数是嵌入矩阵。 矩阵维度：vocab_size × d_model（词汇表中每个令牌对应一个 d_model 维向量） 计算：50257 × 1600 = 80,411,200（约 8041 万） 2. 单一及总Transformer 块的参数（共 48 层，每层参数相同） （1）多头自注意力（MHA）的参数 MHA 包含 Q/K/V 投影、输出投影 4 个权重矩阵，且d_k = d_model / num_heads = 1600 / 25 = 64（每个头的维度）： Q/K/V 投影矩阵（3 个）：每个矩阵维度d_model × d_model（因需将 d_model 维向量拆分为 num_heads 个 d_k 维向量，等价于d_model × (num_heads×d_k) = d_model×d_model） 单个投影矩阵参数：1600 × 1600 = 2,560,000 3 个总参数：3 × 2,560,000 = 7,680,000 输出投影矩阵（1 个）：维度d_model × d_model（将 num_heads 个 d_k 维向量拼接后的 d_model 维向量，映射回 d_model 维） 参数：1600 × 1600 = 2,560,000 MHA 单一层总参数：7,680,000 + 2,560,000 = 10,240,000（1024 万） （2）前馈网络（FFN，SwiGLU 架构）的参数 FFN 包含 3 个权重矩阵（W1、W2、W3），维度分别为d_ff×d_model、d_model×d_ff和d_ff×d_model： W1（输入→内层）：6400 × 1600 = 10,240,000（1024 万） W2（内层→输出）：1600 × 6400 = 10,240,000（1024 万） W3（输入→内层）：6400 × 1600 = 10,240,000（1024 万） FFN 单一层总参数：10,240,000 * 3 = 30,720,000（3072 万） （3）2 个 RMSNorm 层参数 每个 RMSNorm 的增益参数 $g$ 维度：(d_model, )，(1600 个参数 / 层） 2 个 RMSNorm 总参数：$2 \\times 1600 = 3,200$（3200 个 / 层） 预归一化 Transformer 块包含 2 个 RMSNorm 层：分别在 MHA 前和 SwiGLU 前。 （4）Transformer 块总参数 ROPE 没有需要训练的参数，不变参数全部预计算并缓存。 计算：MHA 参数 + FFN 参数 + RMSNorm 参数 = 10,240,000 + 30,720,000 + 3,200 = 40,963,200（4096.3200 万 / 层） 48 层总参数：48 × 40,963,200 = 1,966,233,600（约 19.66 亿） 3. 归一化层（RMSNorm） RMSNorm 的增益参数 $g$ 维度：(d_model, )，(1600 个参数 / 层） 4. 输出投影层（LM Head，与嵌入层权重不共享） 作用：将 Transformer 输出的 d_model 维向量映射到词汇表维度，预测下一个令牌。 矩阵维度：vocab_size × d_model 计算：50257 × 1600 = 80,411,200（约 8041 万） 将所有组件参数相加： $$ \\begin{align*} \\text{总参数} \u0026= 80,411,200 + 1,966,233,600 + 1,600 + 80,411,200 \\ \u0026= 2,127,057,600 \\end{align*} $$ 答案：总可训练参数约 21.28 亿，加载该模型需要占用约 8 GB 内存。 (b) 明确完成 GPT-2 XL 型模型前向传播所需的所有矩阵乘法操作。这些矩阵乘法总共需要多少浮点运算次数（FLOPs）？假设输入序列长度等于上下文长度（context_length）。列出所有矩阵乘法操作（含描述），并给出总浮点运算次数。 矩阵乘法操作 维度说明 词嵌入投影（Embedding） 通常只是查表，无矩阵乘法 多头注意力 Q/K/V 投影 每层：(seq_len, d_model) × (d_model, d_model) -\u003e (seq_len, d_model)（Q、K、V 各 1 次，共 3 次） 点积注意力分数计算 每层：(seq_len, d_k) × (d_k, seq_len) -\u003e (seq_len, seq_len) 点积注意力值加权求和计算 每层：(seq_q, seq_k) × (seq_k, d_v) -\u003e (seq_q, d_v) 多头注意力输出投影 每层：(seq_len, d_model) × (d_model, d_model) -\u003e (seq_len, d_model) 前馈网络第一层（W1） 每层：(seq_len, d_model) × (d_model, d_ff) -\u003e (seq_len, d_ff) 前馈网络第二层（W2） 每层：(seq_len, d_ff) × (d_ff, d_model) -\u003e (seq_len, d_model) 前馈网络第二层（W3） 每层：(seq_len, d_model) × (d_model, d_ff) -\u003e (seq_len, d_ff) 输出层投影（LM Head） (seq_len, d_model) × (d_model, vocab_size) -\u003e (seq_len, vocab_size) 当 seq_len = context_length = 1024，GPT-2 XL一次完整的前向传播（序列长度1024）大约需要 4.20万亿次浮点运算（4.20 TFLOPs)。 (c) 根据上述分析，模型的哪些部分消耗的浮点运算次数（FLOPs）最多？ FLOPs分布: 注意力Q/K/V投影: 17.96% 点积注意力分数计算: 0.15% 点积注意力权重值计算: 0.15% 注意力输出投影: 5.99% 前馈网络第一层: 23.94% 前馈网络第二层: 23.94% 前馈网络第三层: 23.94% 输出层: 3.92% 前馈网络总计: 71.83% 注意力总计: 24.25% 从以上计算可以看出，前馈网络是计算量最大的部分，在 GPT-2 XL 中约占总 FLOPs 的71.83%。这主要因为其内部有一个从 d 到 d_ff（通常4倍于d）的大维度矩阵乘法。其次是**注意力模块中的Q/K/V投影，**约占总 FLOPs 的17.96%。 (d) 对 GPT-2 小模型（12 层、d_model=768、12 个注意力头）、GPT-2 中模型（24 层、d_model=1024、16 个注意力头）和 GPT-2 大模型（36 层、d_model=1280、20 个注意力头）重复上述分析。随着模型规模增大，Transformer 语言模型的哪些部分占总浮点运算次数（FLOPs）的比例会增加或减少？针对每个模型，给出各组件及其对应的浮点运算次数占前向传播总浮点运算次数的比例；此外，用 1-2 句话描述模型规模变化如何影响各组件浮点运算次数的占比。 下表计算了不同规模的GPT-2模型在序列长度为 1024 时，各组件 FLOPs 占总量的比例。 模型组件 GPT-2 Small GPT-2 Medium GPT-2 Large GPT-2 XL 趋势说明 多头注意力 Q/K/V投影 13.84% 16.51% 17.47% 17.96% 占比小幅增加并趋于稳定。其计算量（~6SLd²）与模型维度d²成正比，增长速度快于与d成正比的组件，但慢于前馈网络。 点积注意力分数计算 0.51% 0.34% 0.23% 0.15% 占比急剧下降。其计算量（~2S²Ld_k）仅与序列长度S²和头维度d_k相关，当d增大而S固定时，占比被显著稀释。 点积注意力加权求和计算 0.51% 0.34% 0.23% 0.15% 趋势同“分数计算”，原因完全相同。 多头注意力输出投影 4.61% 5.50% 5.82% 5.99% 占比小幅增加并趋于稳定。原因同Q/K/V投影，计算量（~2SLd²）与d²成正比。 前馈网络 (三层) 55.36% 66.04% 69.89% 71.83% 占比显著且持续增加，是总FLOPs的绝对主体。其计算量（~2SLd·d_ff，通常d_ff=4d）与d²成正比，且因层数L的累加效应，增长最快。 输出","date":"2025-06-14","objectID":"/cs336-assign1/:3:2","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"三、训练 Transformer 语言模型 ","date":"2025-06-14","objectID":"/cs336-assign1/:4:0","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"3.1 交叉熵损失 Transformer 语言模型会为长度为 $m+1$ 的序列 $x$ 和每个位置 $i=1,\\ldots,m$ 定义分布 $p_{\\theta}(x_{i+1} | x_{1:i})$。 给定由长度为 $m$ 的序列组成的训练集 $D$，我们定义标准的交叉熵（负对数似然）损失函数： $$ \\ell(\\theta; D) = \\frac{1}{|D|} \\sum_{x \\in D} \\sum_{i=1}^{m} -\\log p_{\\theta}(x_{i+1} | x_{1:i}) $$ Transformer 的单次前向传播会同时输出所有 $i=1,\\ldots,m$ 对应的 $p_{\\theta}(x_{i+1} | x_{1:i})$，其中 $|D|$ 为训练集大小 (batch_size)。 具体来说，Transformer 会为每个位置 $i$ 计算对数几率（logits）$o_i \\in \\mathbb{R}^{V}$，由此可得： $$ p(x_{i+1} | x_{1:i}) = \\text{softmax}(o_i)[x_{i+1}] = \\frac{\\exp(o_i[x_{i+1}])}{\\sum_{a=1}^{V} \\exp(o_i[a])} $$ 交叉熵损失通常基于对数几率向量 $o_i \\in \\mathbb{R}^{V}$ 和目标值 $x_{i+1}$ 定义。与 softmax 类似，实现交叉熵损失时需要注意数值稳定性问题。 我们已经实现了 softmax 的稳定版本，对其取自然对数得 log_softmax： $$ \\log\\left(\\frac{e^{x_i}}{\\sum_j e^{x_j}}\\right) = \\log\\left(\\frac{e^{x_i-m}}{\\sum_j e^{x_j-m}}\\right) = (x_i - m) - \\log\\sum_j e^{x_j-m} $$ Problem（cross_entropy）：实现交叉熵 import torch from .softmax import log_softmax def cross_entropy(inputs: torch.Tensor, targets: torch.Tensor): # inputs: (batch_size, vocab_size) # targets: (batch_size, ) # (batch_size, vocab_size) D = inputs.shape[0] # 1. 计算softmax概率 probs = log_softmax(inputs, dim=-1) # 2. 提取目标位置的概率 p = probs[torch.arange(D), targets] # 3. 计算平均损失（除以batch_size） return -torch.mean(p)","date":"2025-06-14","objectID":"/cs336-assign1/:4:1","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"3.2 学习率调整 Problem（learning_rate_tuning）：调整学习率 如前所述，学习率是影响训练效果最重要的超参数之一。在我们的简单示例中实际验证这一点：使用上述 SGD 示例，分别尝试另外三个学习率值（1e1、1e2、1e3），仅训练 10 次迭代。观察每个学习率对应的损失变化：是衰减更快、更慢，还是发散（即训练过程中损失增加）？ (cs336-basics) (base) koschei@192 assignment1-basics % uv run ./cs336_basics/sgd.py learing rate: 10.0 step1 , loss: 20.765413284301758 step2 , loss: 13.289864540100098 step3 , loss: 9.796720504760742 step4 , loss: 7.66488790512085 step5 , loss: 6.208559036254883 step6 , loss: 5.14760684967041 step7 , loss: 4.341323375701904 step8 , loss: 3.709784507751465 step9 , loss: 3.203690767288208 step10, loss: 2.7907707691192627 (cs336-basics) (base) koschei@192 assignment1-basics % uv run ./cs336_basics/sgd.py learing rate: 100.0 step1 , loss: 29.470537185668945 step2 , loss: 29.470535278320312 step3 , loss: 5.0563435554504395 step4 , loss: 0.12100967764854431 step5 , loss: 1.2657409207190063e-16 step6 , loss: 1.4107469187345678e-18 step7 , loss: 4.750480809550992e-20 step8 , loss: 2.8298939276754454e-21 step9 , loss: 2.427666298147088e-22 step10, loss: 2.697406997941209e-23 (cs336-basics) (base) koschei@192 assignment1-basics % uv run ./cs336_basics/sgd.py learing rate: 1000.0 step1 , loss: 23.761384963989258 step2 , loss: 8577.859375 step3 , loss: 1481531.25 step4 , loss: 164804544.0 step5 , loss: 13349167104.0 step6 , loss: 842485268480.0 step7 , loss: 43250442305536.0 step8 , loss: 1860819142836224.0 step9 , loss: 6.858582164871578e+16 step10, loss: 2.2023668704120668e+18 答案：学习率 10 时损失缓慢衰减；学习率 100 时损失迅速衰减，极速收敛至接近零；学习率 1000 时损失爆炸式增长，明显发散。 ","date":"2025-06-14","objectID":"/cs336-assign1/:4:2","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"3.3 实现 AdamW Problem (adamw)：实现 AdamW import torch import math class AdamW(torch.optim.Optimizer): def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-2): if lr \u003c 0: raise ValueError(f\"无效的学习率：{lr}\") defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay) super().__init__(params, defaults) def step(self, closure=None): loss = None if closure is not None: loss = closure() for group in self.param_groups: # 获取学习率等参数 alpha = group[\"lr\"] beta1, beat2 = group[\"betas\"] eps = group[\"eps\"] weight_decay = group[\"weight_decay\"] for p in group[\"params\"]: if p.grad is None: continue # 获取与参数 p 相关的状态 state = self.state[p] # 从状态中获取迭代次数，若无则初始化为 1 t = state.get(\"t\", 1) # 一阶矩估计 m = state.get(\"m\", torch.zeros_like(p)) # 二阶矩估计 v = state.get(\"v\", torch.zeros_like(p)) # 获取损失相对于p的梯度 g = p.grad.data # 更新一、二阶矩估计 m = beta1 * m + (1 - beta1) * g v = beat2 * v + (1 - beat2) * g * g # 计算当前迭代的调整后学习率 αt alpha_t = alpha * math.sqrt(1 - beat2**t) / (1 - beta1**t) # 更新参数 p.data -= alpha_t * m / (torch.sqrt(v) + eps) # 应用权重衰减 p.data -= alpha * weight_decay * p.data # 递增迭代次数 state[\"t\"] = t + 1 state[\"m\"] = m state[\"v\"] = v return lossProblem（AdamW Accounting）：AdamW 训练的资源核算 计算运行 AdamW 所需的内存和计算资源。假设所有张量都使用 float32 精度。 (a) 运行 AdamW 需要多少峰值内存？ 根据参数、激活值、梯度和优化器状态的内存使用情况分解答案。用批量大小（batch_size）和模型超参数（vocab_size、context_length、num_layers、d_model、num_heads）表示。假设 $d_{ff} = 4 \\times d_{model}$。 为简化计算，激活值的内存使用仅考虑以下组件： Transformer 块 RMSNorm 层 多头自注意力子层：QKV 投影、$Q^{\\top}K$ 矩阵乘法、softmax、值的加权和、输出投影 位置前馈网络：$W_1$ 矩阵乘法、SiLU 激活、$W_2$ 矩阵乘法 最终的 RMSNorm 输出嵌入 对数几率的交叉熵计算 分别给出参数、激活值、梯度和优化器状态的代数表达式，以及总内存的代数表达式。 参数内存： $$ M_{\\text{params}} = 4(2Vd + L(16d^2 + 2d) + d) $$ 其中 $V$ 为词表大小，$d$ 为模型维度，$L$ 为层数。 梯度内存： $$ M_{\\text{grad}} = 4(2Vd + L(16d^2 + 2d) + d) $$ 优化器状态内存（AdamW 存储一阶矩和二阶矩）： $$ M_{\\text{opt}} = 8(2Vd + L(16d^2 + 2d) + d) $$ 激活内存（基于中间张量的保守估计）： $$ M_{\\text{act}} = 4[L(16BTd + 2BhT^2) + BTd + 2BTV] $$ 其中 $B$ 为批次大小，$T$ 为上下文长度，$h$ 为注意力头数。 总峰值内存： $$ M_{\\text{total}} = 16(2Vd + L(16d^2 + 2d) + d) + 4[L(16BTd + 2BhT^2) + BTd + 2BTV] $$ 参考 DeepSeek 给的思路，给出激活内存的计算过程。 激活内存计算过程 激活内存指前向传播中需要存储的中间变量，用于反向传播计算梯度。根据给定的组件，我们逐项计算每个组件的激活内存（以元素数量计）： 1. Transformer 块（共 L 层） 每个 Transformer 层包含以下部分，其激活内存计算如下： RMSNorm(s): 输入和输出形状均为 [B, T, d]，需要存储输出（输入通常来自上一层已存储）。按存储输出计算：B × T × d。 每层有两个 RMSNorm，共 2 × B × T × d。 多头自注意力子层: QKV 投影：通过线性层将输入 [B, T, d] 投影为 Q、K、V。通常合并为一个输出张量，形状 [B, T, 3d]，然后拆分为三个独立的 [B, T, d] 张量。需存储这三个张量，共 3 × B × T × d。 Q⊤K 矩阵乘法：计算注意力分数，输出形状 [B, h, T, T]，需存储。元素数量为 B × h × T × T。 softmax：对注意力分数进行归一化，输出形状与输入相同，需存储。元素数量为 B × h × T × T。 加权和：将注意力权重与 V 相乘，得到每个头的输出，然后合并多头，输出形状 [B, T, d]，需存储。元素数量为 B × T × d。 输出投影：线性层，输入 [B, T, d]，输出 [B, T, d]，需存储。元素数量为 B × T × d。 位置前馈网络: W1 矩阵乘法：将输入 [B, T, d] 投影到 [B, T, 4d]（因 d_ff = 4 × d），需存储。元素数量为 4 × B × T × d。 SiLU 激活：输入和输出均为 [B, T, 4d]，需存储输出。元素数量为 4 × B × T × d。 W3 矩阵乘法：将输入 [B, T, d] 投影到 [B, T, 4d]（因 d_ff = 4 × d），需存储。元素数量为 4 × B × T × d。 GLU门控：输入和输出[B, T, 4d]，需存储输出。元素数量为 4 × B × T × d。 W2 矩阵乘法：将 [B, T, 4d] 投影回 [B, T, d]，需存储。元素数量为 B × T × d。 此外，每个 Transformer 层还有残差连接，需要存储层的输入（来自上一层输出）和最终输出。但这些通常已在其他组件中考虑或可重用，不单独计算。 汇总一个 Transformer 层的激活内存元素数量： $$ (2 + 3 + 1 + 1 + 4 + 4 + 1) \\times BTd + 2BhT^2 = 16BTd + 2BhT^2 $$ 故根据题目要求，我们采用给定表达式： $$ \\text{每层激活内存（元素）} = 16BTd + 2BhT^2 $$ 2. 其他组件 最终 RMSNorm：输入和输出形状 [B, T, d]，需存储输出。元素数量为 B × T × d。 输出嵌入：将隐藏状态投影到词表，输出 logits 形状 [B, T, V]，需存储。元素数量为 B × T × V。 交叉熵损失：需要 logits 计算损失，logits 已存储；需要计算 log_softmax，临时存储probsB × T × V；标签通常为整数，不占显著激活内存。 3. 总激活内存 综合以上，总激活内存元素数量为： $$ L(16BTd + 2BhT^2) + BTd + 2BTV $$ 转换为字节（乘以 4，因 float32 占 4 字节）： $$ M_{\\text{act}} = 4[L(16BTd + 2BhT^2) + BTd + 2BTV] $$ (b) 针对 GPT-2 XL 规模的模型实例化答案，得到仅依赖于批量大小（batch_size）的表达式。在 80GB 内存中，最多可使用多大的批量大小？ 给出形如 $a \\times B + b$ 的表达式（其中 a、b 为数值），以及最大批量大小的数值。 总内存： $$ M_{\\text{total}} \\approx 14.45B + 31.70 \\text{ GB} $$ 设内存上限为 80 GB： $$ 14.45B + 31.70 \\leq 80 \\implies B \\leq \\frac{80 - 31.70}{14.45} \\approx 3.34 $$ 答案：最大批次大小为 3。 (c) 执行一次 AdamW 步骤需要多少 FLOPs？ 给出代数表达式，并简要说明理由。 GPT-2 XL 参数总数 P = 2,127,057,600 AdamW 更新每个参数约需 10 次浮点操作： 计算一阶矩估","date":"2025-06-14","objectID":"/cs336-assign1/:4:3","tags":["CS336","LLM"],"title":"[斯坦福CS336] 作业一：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"详解 BPE 分词器的高性能优化策略，包括并行化、惰性删除队列、增量更新等技术","date":"2025-06-14","objectID":"/bpe-optimization/","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":" 本文是 CS336 作业一 的延伸阅读，详细介绍 BPE 分词器的优化实现。 ","date":"2025-06-14","objectID":"/bpe-optimization/:0:0","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"背景 文档中推荐使用的 cppyy 在 Mac 和 Linux 环境中有问题。为了追求高性能，我使用 Pybind11 来绑定 C++ 代码：预分词由 Python 处理，而 BPE 归并过程交给 C++。实际最大的瓶颈还是预分词，可以直接用已有的代码 pretokenization_example.py 做分块并行（8核 100s → 16核 30s）。 ","date":"2025-06-14","objectID":"/bpe-optimization/:1:0","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"核心优化策略 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:0","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"1. 并行化处理 使用 OpenMP 并行处理 build_initial_counts() 函数 每个线程维护本地统计结果（ThreadLocal 结构），避免频繁的锁竞争 最终合并各线程的结果到全局统计中 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:1","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"2. 惰性删除的优先级队列 使用最大堆（priority_queue）快速找到最高频的 token pair 采用\"惰性删除\"策略：不直接从队列中删除过期的 pair 当从队列顶部取出 pair 时，检查它是否仍然有效（频率是否与当前统计匹配） 复杂度从 O(NlogN) 降低到 O(KlogN)，其中 K 是需要跳过的过期条目数 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:2","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"3. 增量更新机制 merge_and_update() 函数在合并 token 时，只更新受影响的相邻 pair 维护 pair_positions 索引结构，记录每个 pair 在哪些单词的什么位置出现 避免每次合并后重新扫描所有单词，大幅减少计算量 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:3","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"4. 高效的数据结构 使用整数 ID（0-255）表示字节，避免频繁的字符串操作 自定义哈希函数 PairHash 支持 pair 作为 unordered_map 的键 使用 -1 标记已合并的 token，避免数据移动 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:4","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"5. 内存友好的表示 单词存储为整数向量而不是字符串 词汇表使用 map\u003cint, Bytes\u003e，支持快速 ID 到字节串的查找 特殊 token 在训练结束时添加，不影响核心训练过程 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:5","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"6. 灵活的训练控制 支持指定目标词汇表大小 支持特殊 token（如 \u003cpad\u003e） 返回完整的合并记录，便于后续编码使用 ","date":"2025-06-14","objectID":"/bpe-optimization/:2:6","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"详细示例：优化工作流程 用一个具体例子说明这些优化如何协同工作。 ","date":"2025-06-14","objectID":"/bpe-optimization/:3:0","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"输入数据 words = {\"low\", \"lower\", \"widest\", \"newest\"} counts = [5, 2, 3, 6]初始 token 频率统计（频率相同时按字典序比较）： Token Pair 频率 来源 (“e”,“s”) 9 newest(6) + widest(3) (“s”,“t”) 9 newest(6) + widest(3) (“w”,“e”) 8 newest(6) + lower(2) (“l”,“o”) 7 low(5) + lower(2) (“o”,“w”) 7 low(5) + lower(2) 频率相同时的字典序比较： \"es\" 对应 (“e”,“s”) \"st\" 对应 (“s”,“t”) 字典序比较：\"es\" \u003c \"st\"，所以 (\"e\",\"s\") 的优先级低于 (\"s\",\"t\") 在最大堆中，优先级低的会下沉，所以堆顶是 (\"s\",\"t\")。 ","date":"2025-06-14","objectID":"/bpe-optimization/:3:1","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"惰性删除队列工作流程 第一次合并：合并 (\"s\",\"t\") 为新 token 256 初始队列状态（最大堆，堆顶优先）： 堆顶: (\"s\",\"t\"):9 \u003c-- 将被合并 (\"e\",\"s\"):9 (\"w\",\"e\"):8 (\"l\",\"o\"):7 (\"o\",\"w\"):7 合并操作的影响： 单词 “newest”：[110,101,119,101,115,116] → [110,101,119,101,256,-1] 单词 “widest”：[119,105,100,101,115,116] → [119,105,100,101,256,-1] 增量更新（而非重新计算全部）： // 对于 \"newest\"： // 删除受影响 pairs: (\"e\",\"s\"):6, (\"s\",\"t\"):6 // 添加新 pairs: (\"e\",256):6 // 对于 \"widest\"： // 删除受影响 pairs: (\"e\",\"s\"):3, (\"s\",\"t\"):3 // 添加新 pairs: (\"e\",256):3 队列更新（惰性方式）： 不立即删除队列中的旧条目 将新 pairs 推入队列：(\"e\",256):9 队列现在包含新旧混合条目 下一次获取最高频 pair 时： while (!pair_queue.empty()) { best_info = pair_queue.top(); pair_queue.pop(); auto it = pair_counts.find(best_info.pair); if (it != pair_counts.end() \u0026\u0026 it-\u003esecond == best_info.count) { break; // 有效，使用它 } // 否则，这是过期条目，继续检查下一个 } ","date":"2025-06-14","objectID":"/bpe-optimization/:3:2","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"增量更新的具体数值变化 合并前全局统计： pair_counts = { (\"e\",\"s\"):9, (\"s\",\"t\"):9, (\"w\",\"e\"):8, (\"l\",\"o\"):7, (\"o\",\"w\"):7, (\"n\",\"e\"):6, (\"e\",\"w\"):6, ... }合并 (\"s\",\"t\") 后的增量更新： 对于 “newest”（频率 6）： 删除左相邻 (\"e\",\"s\")：pair_counts[(\"e\",\"s\")] -= 6 → 从 9 到 3 删除 (\"s\",\"t\") 自身：pair_counts[(\"s\",\"t\")] -= 6 → 从 9 到 3 添加新左相邻 (\"e\",256)：pair_counts[(\"e\",256)] += 6 → 从 0 到 6 对于 “widest”（频率 3）： 删除左相邻 (\"e\",\"s\")：pair_counts[(\"e\",\"s\")] -= 3 → 从 3 到 0 删除 (\"s\",\"t\") 自身：pair_counts[(\"s\",\"t\")] -= 3 → 从 3 到 0 添加新左相邻 (\"e\",256)：pair_counts[(\"e\",256)] += 3 → 从 6 到 9 ","date":"2025-06-14","objectID":"/bpe-optimization/:3:3","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"并行处理优势 假设有 8 个线程，处理 100 万个单词： 优化前（串行）： 单线程扫描 100 万单词，统计所有相邻 pair 时间复杂度：O(N×M)，其中 M 是平均单词长度 优化后（并行）： #pragma omp parallel for schedule(static) for (size_t i = 0; i \u003c 1000000; ++i) { // 每个线程处理约 125,000 个单词 // 线程本地统计，无锁竞争 } // 最后合并线程本地结果 性能提升： 理想情况下：8 线程加速 ≈ 6-7 倍 实际考虑线程创建、合并开销：加速 ≈ 5-6 倍 ","date":"2025-06-14","objectID":"/bpe-optimization/:3:4","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"内存效率对比 方法 存储 “newest” 合并 “st” 后 内存占用 字符串数组 [\"n\",\"e\",\"w\",\"e\",\"s\",\"t\"] [\"n\",\"e\",\"w\",\"e\",\"st\"] 需要移动/复制字符串 整数ID+标记 [110,101,119,101,115,116] [110,101,119,101,256,-1] 只修改两个整数 ","date":"2025-06-14","objectID":"/bpe-optimization/:3:5","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"性能对比 测试机器：autodl Xeon(R) Platinum 8352V 32 核心 CPU 60GB 内存，预分词使用 24 个核心并行工作。 数据 版本 预分词 BPE归并训练 总时间 TinyStoriesV2-GPT4-train Python 29.65s 10min++ 不可接受 TinyStoriesV2-GPT4-train Cpp 未优化归并 27.337s 366.644s 394.16s TinyStoriesV2-GPT4-train Cpp 优化归并 26.767s 1.081s 28.03s TinyStoriesV2-GPT4-train Rust 优化预分词 67.261s - - Python 的 regex 库底层 C 语言优化非常出色，C++ 的 regex 库对 Unicode 支持不完善，Rust 性能反而比 Python 慢一倍。正如文档所说：\"…but the regex package in Python is, if anything, even faster.\" ","date":"2025-06-14","objectID":"/bpe-optimization/:4:0","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["LLM"],"content":"总结 这些优化使得算法能够高效处理大规模文本数据，特别是在构建初始统计和迭代合并阶段表现出色： 并行化处理加速了初始计数 惰性删除的优先级队列减少了维护开销 增量更新机制避免了不必要的重复计算 最终实现了从 10 分钟以上到约 1 秒的性能提升，提速超过 300 倍。 ","date":"2025-06-14","objectID":"/bpe-optimization/:5:0","tags":["CS336","LLM","BPE","性能优化"],"title":"BPE 分词器高性能优化：从 10 分钟到 1 秒的实践","uri":"/bpe-optimization/"},{"categories":["Guides"],"content":"写在开头 当今，大部分平台已逐步从“一次性买断”过渡到“订阅制”，1Password 8 也是如此。公司为了维持经营、继续发展做出此番举动也并非不可理解。 截止至 2025 年 3 月，1Password 8 个人版每年收费 USD $35.88，Teams 基础版 (10 人) 每年收费 USD $239.4。 而只要你申请通过了 1Password for Open Source Project，你就可以免费获得永久的 1Password for Teams 订阅，这实在是太良心了。 当你看到 1Password for Open Source 的 GitHub 页面上所写的这段话便可了解他们的意图。 It’s fair to say that 1Password wouldn’t exist without the open source community, so we want to give back and help teams be more productive and secure. 说实话，1Password 的出现根本离不开开源的社群，因此我们决定回馈并帮助那些开源团队变得更加高效且安全。 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:1:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"申请要求 1Password 对于开源项目的要求其实并不严格 你需要符合以下其一要求： 你是一个已创建至少 30 天且活跃的开源项目的核心贡献者 你是一个开源社区见面会/活动/会议的组织者 另外，你的项目必须： 使用标准开源许可证 非商业性质 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:2:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"申请流程 创建 1Password Teams 账户 前往注册链接，填写注册信息 注册之后你会发现此时账户处于试用状态，不必担心 邀请至少一位其他用户加入团队的拥有者用户组 (Owners group) 申请时请填写此表格并在此仓库中提交一个新的issue。 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:3:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"申请完成后 前往团队管理界面 \u003e 账单，你将不会再看到任何有关 到期 相关的字样。 1Password Team 的所有者看不到其他用户的私有数据，但是可以在 Shared 共享保险箱中与他人共享项目，除此之外与 1Password 个人版并无太大差异。 但是你需要注意: 该会员资格不得被转让或出售，因此这个 1Password for Teams 的所有者只能是你；另外，如果你的开源项目不再活跃，1Password 可能会收回你的会员资格。 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:4:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"1Password 好处都有什么? 支持 macOS, iOS, Windows, Android, Linux, 浏览器插件和命令行 可以生成 SSH Key 公私钥，并使用 1Password-CLI 将其用于 Git Commit 签名或其他自动化 Workflow 调用 1Password-CLI 或者电脑唤醒后可以通过 Windows Hello / Touch ID / Face ID 快速鉴权 (可能之后会支持 Vision Pro 的 Optic ID)，不过电脑重启后或长时间未登录需要强制手动输入主密码 相比于每个网站都使用类似的密码，使用 1Password 可以让你为每个网站都生成不同的密码，以防撞库导致其他网站密码同样泄露 相比在浏览器中保存密码，1Password 可以 减少 因计算机被 Malware 潜入而导致账户密码被盗的情况 自建 Bitwarden Self Host 是一个不错的低成本方案，但是其存在诸多不稳定因素，一旦服务器宕机数据便无法访问。我个人认为 1Password 团队还是比我的运维技术更强的。🙃 其余的可能就需要你探索了… ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:5:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Build"],"content":"安装环境依赖 brew install automake autoconf libtool pkg-config texinfo coreutils gnu-getopt \\ python@3 cmake ninja ccache bison byacc gettext wget pcre maven llvm@16 openjdk@17 npmDoris master 目前只支持 jdk17 版本 需要设置的环境变量 export JAVA_HOME=\"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\" export PATH=$JAVA_HOME/bin:$PATH export PATH=\"/opt/homebrew/opt/openjdk@17/bin:$PATH\" export PATH=\"/opt/homebrew/opt/texinfo/bin:$PATH\"","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:1:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"拉取自己的代码 拉取代码 cd ~ mkdir DorisDev cd DorisDev git clone https://github.com/GitHubID/doris.git 设置环境变量 export DORIS_HOME=~/DorisDev/doris export PATH=$DORIS_HOME/bin:$PATH ","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:2:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"下载 Doris 编译依赖 Apache Doris Third Party Prebuilt页面有所有第三方库的源码，可以直接下载doris-thirdparty-source.tgz获得。 可以在Apache Doris Third Party Prebuilt页面直接下载预编译好的第三方库，省去编译第三方库的过程，参考下面的命令。 cd thirdparty rm -rf installed # Intel 芯片 curl -L https://github.com/apache/doris-thirdparty/releases/download/automation/doris-thirdparty-prebuilt-darwin-x86_64.tar.xz \\ -o - | tar -Jxf - # Apple Silicon 芯片 curl -L https://github.com/apache/doris-thirdparty/releases/download/automation/doris-thirdparty-prebuilt-darwin-arm64.tar.xz \\ -o - | tar -Jxf - # 保证 protoc 和 thrift 能够正常运行 cd installed/bin ./protoc --version ./thrift --version 运行protoc和thrift的时候可能会遇到无法打开，因为无法验证开发者的问题，可以到前往安全性与隐私。点按通用面板中的仍要打开按钮，以确认打算打开该二进制。参考https://support.apple.com/zh-cn/HT202491。 ","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:3:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"修改系统最大文件句柄数 # bash echo 'ulimit -n 65536' \u003e\u003e~/.bashrc # zsh echo 'ulimit -n 65536' \u003e\u003e~/.zshrc","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:4:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"编译 Doris cd $DORIS_HOME sh build.sh","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:5:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"编译过程中可能会遇到高版本的 Node.js 导致的错误 M1 目前没遇到过。 opensslErrorStack: [’error:03000086:digital envelope routines::initialization error’] library: ‘digital envelope routines’ reason: ‘unsupported’ code: ‘ERR_OSSL_EVP_UNSUPPORTED’ 以下命令解决问题。参考https://stackoverflow.com/questions/74726224/opensslerrorstack-error03000086digital-envelope-routinesinitialization-e #指示Node.js使用旧版的OpenSSL提供程序 export NODE_OPTIONS=--openssl-legacy-provider","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:6:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"编译过程中可能会遇到 jni.h not found Mac 的 JDK 在更深一层目录。 export JAVA_HOME=\"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\" export PATH=$JAVA_HOME/bin:$PATH","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:7:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"配置 Debug 环境 # 将编译好的包cp出来 cp -r output ../doris-run # 配置FE/BE的conf，用默认的也行吧 1、IP、目录 2、BE 额外配置 min_file_descriptor_number = 10000","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:8:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"开始用 IDE 进行 Debug 参考官方OK CLion Mac 调试 BE IntelliJ IDEA Mac 调试 FE ","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:9:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":null,"content":"关于 LoveIt","date":"2019-08-02","objectID":"/about/","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"  LoveIt 是一个由  Dillon 开发的简洁、优雅且高效的 Hugo 博客主题。 它的原型基于 LeaveIt 主题 和 KeepIt 主题。 Hugo 主题 LoveIt ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特性 ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持 Plausible Analytics  支持 Yandex Metrica  支持搜索引擎的网站验证 (Google, Bind, Yandex 和 Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 ","date":"2019-08-02","objectID":"/about/:1:1","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"外观和布局  桌面端/移动端 响应式布局  浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 76 种社交链接  支持多达 24 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Facebook comments 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 utterances 评论系统  支持 giscus 评论系统 ","date":"2019-08-02","objectID":"/about/:1:2","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightGallery 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $\\KaTeX$ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 cookieconsent 的 Cookie 许可横幅  支持人物标签的 shortcode … ","date":"2019-08-02","objectID":"/about/:1:3","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"许可协议 LoveIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特别感谢 LoveIt 主题中用到了以下项目，感谢它们的作者： modern-normalize Font Awesome Simple Icons Animate.css autocomplete Lunr.js algoliasearch lazysizes object-fit-images Twemoji emoji-data lightGallery clipboard.js Sharer.js TypeIt $\\KaTeX$ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 LoveIt","uri":"/about/"}]