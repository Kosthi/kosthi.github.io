[{"categories":["LLM"],"content":" title: “[斯坦福CS336]作业五：对齐与推理强化学习” subtitle: \"\" date: 2026-01-13T18:12:00+08:00 lastmod: 2026-01-13T18:13:00+08:00 draft: false author: “Koschei” authorLink: \"\" description: \"\" images: [] resources: name: \"\" src: \"\" tags: [“CS336”, “LLM”] categories: [“LLM”] ","date":"2026-01-13","objectID":"/cs336-assign2/:0:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"lightgallery: true 作业5：对齐与推理强化学习 ","date":"2026-01-13","objectID":"/cs336-assign2/:1:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"1 作业概述 本次作业中，你将获得训练语言模型解决数学问题时进行推理的实践经验。 ","date":"2026-01-13","objectID":"/cs336-assign2/:2:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"需实现的内容 针对 Hendrycks 等人 [2021] 提出的竞赛数学问题数据集 MATH，实现零样本提示基线模型。 利用更强推理模型（DeepSeek R1，DeepSeekAI 等人，2025）的推理轨迹进行有监督微调（SFT）。 采用专家迭代（Expert Iteration）方法，通过验证奖励提升推理性能。 采用组相对策略优化（GRPO）方法，通过验证奖励提升推理性能。 对于感兴趣的同学，我们将在未来几天发布可选作业部分：使语言模型与人类偏好对齐。 ","date":"2026-01-13","objectID":"/cs336-assign2/:2:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"需运行的内容 评估 Qwen 2.5 Math 1.5B 模型的零样本提示性能（作为基线）。 利用 R1 的推理轨迹对 Qwen 2.5 Math 1.5B 进行有监督微调（SFT）。 利用验证奖励对 Qwen 2.5 Math 1.5B 进行专家迭代训练。 利用验证奖励对 Qwen 2.5 Math 1.5B 进行 GRPO 训练。 作业地址： Assignment5-alignment GitHub仓库 接下来我将分享完成作业的一部分细节和心得。 ","date":"2026-01-13","objectID":"/cs336-assign2/:2:2","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2 语言模型的推理能力 ","date":"2026-01-13","objectID":"/cs336-assign2/:3:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2.1 动机 语言模型的显著应用场景之一是构建能处理多种自然语言处理任务的通用系统。本次作业将聚焦语言模型的一个新兴应用场景：数学推理。我们将以此为测试平台，搭建评估体系、执行有监督微调，并探索利用强化学习（RL）训练语言模型进行推理的方法。 本次作业与以往作业有两处不同： 不再使用之前作业中的语言模型代码库和模型。理想情况下，我们希望使用之前作业中训练的基础语言模型，但微调这些模型无法获得令人满意的结果 —— 它们的能力太弱，无法展现复杂的数学推理能力。因此，我们将切换到一个可访问的现代高性能语言模型（Qwen 2.5 Math 1.5B Base），并在此基础上开展大部分工作。 引入新的基准数据集评估语言模型。此前，我们认为交叉熵可作为许多下游任务的良好替代指标。但本次作业的核心是缩小基础模型与下游任务之间的差距，因此必须使用独立于交叉熵的评估方法。我们将采用 Hendrycks 等人 [2021] 提出的 MATH 12K 数据集，该数据集包含具有挑战性的高中竞赛数学问题。我们将通过对比模型输出与参考答案来评估语言模型的性能。 ","date":"2026-01-13","objectID":"/cs336-assign2/:3:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"2.2 思维链推理与推理强化学习 语言模型领域近期的一个热门趋势是利用思维链（Chain-of-Thought）推理提升各类任务的性能。思维链指的是逐步推理问题的过程，在得出最终答案前生成中间推理步骤。 语言模型的思维链推理 早期的思维链方法通过 “草稿本”（scratchpad）将问题分解为中间步骤，微调语言模型解决算术等简单数学任务 [Nye 等人，2021]。其他研究则通过提示强模型在回答前 “逐步思考”，发现这能显著提升其在小学算术题等数学推理任务上的性能 [Wei 等人，2023]。 基于专家迭代的推理学习 自训练推理器（STaR）[Zelikman 等人，2022] 将推理构建为一个自举循环：预训练模型首先生成多样化的思维链（CoT），仅保留能得出正确答案的思维链，然后利用这些 “专家” 轨迹进行微调。重复该循环可提升语言模型的推理能力和解题率。STaR 证明，这种基于专家迭代 [Anthony 等人，2017] 的方法，通过对生成答案进行自动字符串匹配验证，无需人工编写推理轨迹即可自举推理能力。 基于验证奖励的推理强化学习（o1、R1） 近期研究探索了使用更强大的强化学习算法结合验证奖励来提升推理性能。OpenAI 的 o1（及后续的 o3/o4）[OpenAI 等人，2024]、DeepSeek 的 R1 [DeepSeek-AI 等人，2025] 以及 Moonshot 的 kimi k1.5 [Team 等人，2025] 均采用策略梯度方法 [Sutton 等人，1999] 在数学和代码任务上进行训练，通过字符串匹配或单元测试验证答案正确性，在竞赛数学和编程任务上取得了显著性能提升。后续研究如 Open-R1 [Face，2025]、SimpleRL-Zoo [Zeng 等人，2025] 和 TinyZero [Pan 等人，2025] 证实，即使在参数规模仅为 1.5B 的模型上，基于验证奖励的纯强化学习也能提升推理性能。 实验设置：模型与数据集 在后续章节中，我们将逐步采用更复杂的方法训练基础语言模型，使其能通过逐步推理解决数学问题。本次作业将使用 Qwen 2.5 Math 1.5B Base 模型，该模型基于 Qwen 2.5 1.5B 模型，在高质量合成数学预训练数据上进行了持续预训练 [Yang 等人，2024]。MATH 数据集可在 Together 集群的 /data/a5-alignment/MATH 路径下获取。 开源替代数据集（面向开源审计者） 由于版权限制，MATH 数据集未公开。若你在本地完成作业，可使用以下开源数学推理数据集： Countdown [Pan 等人，2025]：基于英国电视节目《Countdown》的简单合成任务，是小规模推理强化学习的常用测试平台，获取链接：[此处]。 GSM8K [Cobbe 等人，2021a]：小学算术题数据集，难度低于 MATH，适合调试代码正确性并熟悉推理强化学习流程，获取链接：[此处]。 Tulu 3 SFT Math [Lambert 等人，2025]：使用 GPT-4o 和 Claude 3.5 Sonnet 生成的合成数学问题，由于是合成数据，部分答案（甚至问题）可能存在错误，获取链接：[此处]。 其他数学 SFT 数据集：[此处链接]。 若数据集中未直接提供简短真实标签（如 1/2），可使用 Math-Verify 等数学答案解析器处理真实标签列。 ","date":"2026-01-13","objectID":"/cs336-assign2/:3:2","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"3 评估零样本 MATH 性能 我们首先评估基础语言模型在 MATH 数据集的 5K 测试集上的性能。建立该基线有助于理解后续每种方法对模型行为的影响。 ","date":"2026-01-13","objectID":"/cs336-assign2/:4:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"作业题（数学基线性能）：4 分 (a) 编写脚本评估 Qwen 2.5 Math 1.5B 模型在 MATH 数据集上的零样本性能 该脚本需要完成以下任务： 从 /data/a5-alignment/MATH/validation.jsonl 加载 MATH 验证集样本； 使用 r1_zero 提示词将这些样本格式化为语言模型可接收的字符串提示词； 为每个样本生成模型输出； 计算评估指标； 将样本、模型生成结果以及对应的评估分数序列化保存到磁盘，以便后续作业题进行分析。 在实现过程中，编写一个如下所示的 evaluate_vllm 方法会很有帮助，后续你可以复用该方法： def evaluate_vllm( vllm_model: LLM, reward_fn: Callable[[str, str], dict[str, float]], prompts: List[str], eval_sampling_params: SamplingParams ) -\u003e None: \"\"\" 针对一组提示词评估语言模型性能， 计算评估指标，并将结果序列化保存到磁盘。 \"\"\"提交要求：一份用于评估零样本 MATH 数据集基线性能的脚本。 See at [eval.py][https://github.com/Kosthi/assignment5-alignment/blob/main/eval.py] (b) 在 Qwen 2.5 Math 1.5B 模型上运行你的评估脚本 统计模型生成结果分别落入以下三类的数量： 格式奖励和答案奖励均为 1（完全正确）； 格式奖励为 1、答案奖励为 0（格式正确，答案错误）； 格式奖励和答案奖励均为 0（格式和答案均错误）。 观察至少 10 个格式奖励为 0 的案例，你认为问题出在基础模型的输出上，还是出在解析器上？为什么？再观察至少 10 个格式奖励为 1 但答案奖励为 0 的案例，你有什么看法？ 提交要求：关于模型和奖励函数性能的分析说明，包含各类案例的示例。 1. 数量统计 根据日志开头的汇总信息（num_examples=5000）及各类计数，模型生成结果分布如下： 格式奖励和答案奖励均为 1（完全正确）：count(fmt=1,ans=1)=139 例。 格式奖励为 1、答案奖励为 0（格式正确，答案错误）：count(fmt=1,ans=0)=693 例。 格式奖励和答案奖励均为 0（格式和答案均错误）：count(fmt=0,ans=0)=4168 例。 2. 对“格式奖励为 0”案例的观察 在日志提供的至少10个此类案例中（标记为 sample_fmt0_ans0_examples=10），问题主要出在基础模型的输出上，而非解析器。 主要原因：这些失败案例的共同点是模型没有遵循指定的输出格式。根据日志，正确的格式应包含清晰的 \u003cthink\u003e 推理过程和用 \u003canswer\u003e 标签包裹的最终答案。然而，问题模型输出经常出现： 格式结构混乱：例如在回答 “What is the positive difference between $120%$ of 30 and $130%$ of 20?” 时，模型在 \u003cthink\u003e 标签内直接给出了答案，并且混入了 \u003cend think\u003e \u003canswer\u003e 等未定义的标签，导致解析失败。 输出无关内容与符号：例如在回答函数逆问题 “Let $f(x)=7x+5$…” 时，模型的 \u003cthink\u003e 内容包含大量无关代码片段、乱码字符（如 “\u003c/\u003cbr\u003e下一格*/{ */”），甚至插入图片链接，完全偏离了数学推理。 推理与答案未分离：模型经常在思考部分就写下“答案是…”，或者最终答案没有用要求的标签包裹。 这些现象表明，基础模型在遵循严格的结构化输出指令上存在困难，未能生成可供解析器正确处理的文本。 3. 对“格式奖励为 1 但答案奖励为 0”案例的观察 在日志随后提供的至少10个此类案例中（标记为 sample_fmt1_ans0_examples=10），模型成功遵循了格式要求，但答案本身是错误的。 主要看法：这揭示了模型的核心能力局限。在格式正确的情况下，错误类型包括： 数学计算错误：例如计算 $i^5+i^{-25}+i^{45}$ 时，模型得出 $2i$，但正确答案应为 $i$。 逻辑推理错误：例如在求满足不等式 $|x|+1\u003e7$ 和 $|x+1|\\le7$ 的整数和时，模型正确列出了计算步骤，但错误地将 -6 包含在内，得到和 -21，正确答案应为 -15。 最终答案表述不精确：例如问垂直线条数量，模型在 \u003canswer\u003e 中正确给出了导致分母为零的值 “-3$ and $2$”，却没有将其转化为最终答案“2条”。 这表明，模型在一定程度上学会了“模仿”解题的格式和框架，但其数学推理、计算准确性和对问题最终要求的理解仍然不足。 (c) Qwen 2.5 Math 1.5B 模型在 MATH 数据集上的零样本基线性能表现如何？ 提交要求：用 1-2 句话概括评估指标结果。 根据评估日志中的指标（mean_reward=0.0278，且完全正确的比例仅为139/5000≈2.78%），该模型在MATH数据集上的零样本基线性能非常弱，其生成结果在格式和答案上的整体正确率极低，尚不具备可靠解决复杂数学问题的能力。 ","date":"2026-01-13","objectID":"/cs336-assign2/:4:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"4 用于MATH的有监督微调 ","date":"2026-01-13","objectID":"/cs336-assign2/:5:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"问题(sft_experiment)：在MATH数据集上运行SFT（2分）（2个H100小时） 1. 使用Qwen 2.5 Math 1.5B基础模型，在推理SFT示例（在/data/a5-alignment/MATH/sft.jsonl中提供）上运行SFT，改变SFT中唯一示例的数量，范围为{128, 256, 512, 1024}，以及使用完整数据集。调整学习率和批次大小，以在使用完整数据集时至少达到15%的验证准确率。 提交内容： 与不同数据集大小相关的验证准确率曲线。 少量sft的样本反而比大量的更好, 熵也下降的更快更低, 样本多了模型反而 confuse。 2. 过滤推理SFT示例，仅包括产生正确答案的示例。在（完整）过滤数据集上运行SFT，并报告过滤数据集的大小和你达到的验证准确率。 提交内容： 报告数据集的大小和你达到的验证准确率曲线。将你的发现与之前的SFT实验进行比较。 实验暂定 ","date":"2026-01-13","objectID":"/cs336-assign2/:5:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"5 用于MATH的专家迭代 ","date":"2026-01-13","objectID":"/cs336-assign2/:6:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"问题(expert_iteration_experiment)：在MATH数据集上运行专家迭代（2分）（6个H100小时） 在MATH数据集（在/data/a5-alignment/MATH/train.jsonl中提供）上使用Qwen 2.5 Math 1.5B Base模型运行专家迭代，改变每个问题的rollout数量G和SFT步骤中使用的轮数，并使用n_ei_steps = 5。改变每个专家迭代步骤的批次大小（即Db的大小）在{512, 1024, 2048}中。（你不需要尝试这些超参数的所有可能组合。只要足够得出关于每个的结论即可。）记录训练过程中模型响应的熵。确保vLLM在第二个答案标签处终止生成，如SFT部分所做的那样。 提交内容： 与不同rollout配置相关的验证准确率曲线。至少尝试2种不同的rollout计数和轮数计数。 一个在MATH上达到至少15%验证准确率的模型。 一个简短的2句讨论，将你的性能与SFT性能进行比较，以及在EI步骤之间的性能比较。 一个显示训练过程中模型响应熵的图表。 实验暂定 ","date":"2026-01-13","objectID":"/cs336-assign2/:6:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"6 策略梯度入门 ","date":"2026-01-13","objectID":"/cs336-assign2/:7:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业五：对齐与推理强化学习","uri":"/cs336-assign2/"},{"categories":["LLM"],"content":"为什么系统爱好者都应该学习大模型？ 在当今AI技术浪潮中，掌握大模型知识已成为系统开发者的必备技能。通过参与斯坦福CS336大模型系统课程，开始从零构建大模型的实践之旅。这门课程很可能在未来3年内成为系统领域的标杆课程（正如CMU 15-445数据库课程近年来的地位）。 ","date":"2025-06-14","objectID":"/cs336-assign1/:1:0","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业1：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["LLM"],"content":"作业1：构建 Transformer 语言模型 通过以下三个小节实现了一个小型语言模型。 Tokenizer设计与实现 模型架构编码（含Self-Attention机制） 优化器开发 作业地址： Assignment1-Basics GitHub仓库 接下来我将分享完成作业的一部分细节和心得。 2.字节对编码（BPE）分词器 2.1 Unicode 标准 Problem（unicode1）理解 Unicode（1 分） (a) chr(0)返回什么 Unicode 字符？ NULL字符，即ASCII空字符 \u003e\u003e\u003e chr(0) '\\x00'(b) 该字符的字符串表示（__repr__()）与其打印表示有何不同？ repr()函数显示转移序列’\\\\x00’，打印什么都不显示，即空字符 \u003e\u003e\u003e repr(chr(0)) \"'\\\\x00'\" \u003e\u003e\u003e print(chr(0))(c) 该字符出现在文本中时会发生什么？可在 Python 解释器中尝试以下代码验证 空字符虽然在打印时不可见，但仍作为 Python 字符串的一部分，这表明 Python 字符串可以包含不可见的字符，且这些空字符仍然会影响字符串的存储和处理。 \u003e\u003e\u003e chr(0) '\\x00' \u003e\u003e\u003e print(chr(0)) \u003e\u003e\u003e \"this is a test\" + chr(0) + \"string\" 'this is a test\\x00string' \u003e\u003e\u003e print(\"this is a test\" + chr(0) + \"string\") this is a teststring2.2 Unicode 编码 Problem（unicode2）Unicode 编码（1 分） (a) 为什么优先选择在 UTF-8 编码的字节上训练分词器，而非 UTF-16 或 UTF-32？可对比不同编码对各类输入字符串的输出结果。 训练分词器时处理的是字节序列，UTF-8能更紧凑地表示常见字符，减少序列长度，这对模型训练更高效。而且UTF-8向后兼容ASCII，处理英文文本时特别高效。 \u003e\u003e\u003e test_string=\"你好,世界!\" \u003e\u003e\u003e list(test_string.encode(\"utf-8\")) [228, 189, 160, 229, 165, 189, 44, 228, 184, 150, 231, 149, 140, 33] \u003e\u003e\u003e list(test_string.encode(\"utf-16\")) [255, 254, 96, 79, 125, 89, 44, 0, 22, 78, 76, 117, 33, 0] \u003e\u003e\u003e list(test_string.encode(\"utf-32\")) [255, 254, 0, 0, 96, 79, 0, 0, 125, 89, 0, 0, 44, 0, 0, 0, 22, 78, 0, 0, 76, 117, 0, 0, 33, 0, 0, 0](b) 以下函数意图将 UTF-8 字节串解码为 Unicode 字符串，但存在错误。该函数为何不正确？请提供一个导致错误结果的输入字节串示例。 该函数不正确，因为它逐字节解码，这对于多字节UTF-8 字符会失败。单独的字节\\xe4是无效的 UTF-8字符，会引发UnicodeDecodeError 异常。 def decode_utf8_bytes_to_str_wrong(bytestring: bytes): return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring]) \u003e\u003e\u003e decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\")) 'hello' \u003e\u003e\u003e \"你好\".encode(\"utf-8\") b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd' \u003e\u003e\u003e decode_utf8_bytes_to_str_wrong(\"你好\".encode(\"utf-8\")) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e import platform File \"\u003cstdin\u003e\", line 2, in decode_utf8_bytes_to_str_wrong import sys UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data \u003e\u003e\u003e bytes([0xe4,0xbd,0xa0]).decode(\"utf-8\") '你' ## 汉字“你”占用了3个字节(c) 给出一个无法解码为任何 Unicode 字符的两字节序列。 b'\\x80\\x81'是无效的，因为在 UTF-8 中，任何以二进制 10 开头的字节（如 0x80）必须是延续字节，但此处它作为首字节出现，前面没有有效的前导字节。 \u003e\u003e\u003e b'\\x80\\x81'.decode(\"utf-8\") Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e import platform UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte \u003e\u003e\u003e b'\\xe4\\x80\\x81'.decode(\"utf-8\") '䀁' ## 生僻字 䀁(yòu) UTF-8编码 E4 80 812.5 BPE分词器训练实验 1.在预分词之前移除特殊标记 special_tokens = [\"\u003c|endoftext|\u003e\", \"\u003csep\u003e\", \"[SPECIAL]\"] # 注意先转义再用\"|\"分割，在正则表达式中\"|\"表示为或 \u003c|endoftext|\u003e|\u003csep\u003e|[SPECIAL] # \"|\".join(special_tokens) 结果 \u003c\\|endoftext\\|\u003e\\|\u003csep\u003e\\|\\[SPECIAL\\] # Wrong: re.escape(\"|\".join(special_tokens)) 结果 \u003c\\|endoftext\\|\u003e|\u003csep\u003e|\\[SPECIAL\\] # True: \"|\".join([re.escape(token) for token in special_tokens])2.字节对编码（BPE）的优化 文档中推荐使用的cppyy在Mac和Linux环境中有问题，为了追求高性能，使用Pybind11来绑定cpp代码，我的代码中预分词由py处理，而BPE归并过程交给cpp，实际最大的瓶颈还是预分词，可以直接用已有的代码pretokenization_example.py做个分块并行提升最大（8核 100s，16核30s）。 主要包含以下几个关键优化： 并行化处理 使用OpenMP并行处理build_initial_counts()函数 每个线程维护本地统计结果（ThreadLocal结构），避免频繁的锁竞争 最终合并各线程的结果到全局统计中 惰性删除的优先级队列 使用最大堆（priority_queue）快速找到最高频的token pair 采用\"惰性删除\"策略：不直接从队列中删除过期的pair 当从队列顶部取出pair时，检查它是否仍然有效（频率是否与当前统计匹配） 避免每次合并后重建队列，复杂度从O(NlogN)降低到O(KlogN)，其中K是需要跳过的过期条目数 增量更新机制 merge_and_update()函数在合并token时，只更新受影响的相邻pair 维护pair_positions索引结构，记录每个pair在哪些单词的什么位置出现 避免每次合并后重新扫描所有单词，大幅减少计算量 高效的数据结构 使用整数ID（0-255）表示字节，避免频繁的字符串操作 自定义哈希函数PairHash支持pair作为unordered_map的键 使用-1标记已合并的token，避免数据移动 内存友好的表示 单词存储为整数向量而不是字符串 词汇表使用map\u003cint, Bytes\u003e，支持快速ID到字节串的查找 特殊token在训练结束时添加，不影响核心训练过程 灵活的训练控制 支持指定目标词汇表大小 支持特殊token（如\u003cpad\u003e） 返回完整的合并记录，便于后续编码使用 这些优化使得算法能够高效处理大规模文本数据，特别是在构建初始统计和迭代合并阶段表现出色。并行化处理加速了初始计数，惰性删除的优先级队列减少了维护开销，而增量更新机制避免了不必要的重复计算。 用一个例子说明这些优化： 输入数据： words = {\"low\", \"lower\", \"widest\", \"newest\"} counts = [5, 2, 3, 6]初始token频率统计（频率相同时按字典序比较）： Token Pair 频率 来源 (“e”,“s”) 9 newest(6) + widest(3) (“s”,“t”) 9 newest(6) + widest(3) (“w”,“e”) 8 newest(6) + lower(2) (“l”,“o”) 7 low(5) + lower(2) (“o”,“w”) 7 low(5) + lower(2) 频率相同时的字典序比较： \"es\" (对应(“e”","date":"2025-06-14","objectID":"/cs336-assign1/:1:1","tags":["CS336","LLM"],"title":"[斯坦福CS336]作业1：构建 Transformer 语言模型","uri":"/cs336-assign1/"},{"categories":["Guides"],"content":"写在开头 当今，大部分平台已逐步从“一次性买断”过渡到“订阅制”，1Password 8 也是如此。公司为了维持经营、继续发展做出此番举动也并非不可理解。 截止至 2025 年 3 月，1Password 8 个人版每年收费 USD $35.88，Teams 基础版 (10 人) 每年收费 USD $239.4。 而只要你申请通过了 1Password for Open Source Project，你就可以免费获得永久的 1Password for Teams 订阅，这实在是太良心了。 当你看到 1Password for Open Source 的 GitHub 页面上所写的这段话便可了解他们的意图。 It’s fair to say that 1Password wouldn’t exist without the open source community, so we want to give back and help teams be more productive and secure. 说实话，1Password 的出现根本离不开开源的社群，因此我们决定回馈并帮助那些开源团队变得更加高效且安全。 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:1:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"申请要求 1Password 对于开源项目的要求其实并不严格 你需要符合以下其一要求： 你是一个已创建至少 30 天且活跃的开源项目的核心贡献者 你是一个开源社区见面会/活动/会议的组织者 另外，你的项目必须： 使用标准开源许可证 非商业性质 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:2:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"申请流程 创建 1Password Teams 账户 前往注册链接，填写注册信息 注册之后你会发现此时账户处于试用状态，不必担心 邀请至少一位其他用户加入团队的拥有者用户组 (Owners group) 申请时请填写此表格并在此仓库中提交一个新的issue。 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:3:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"申请完成后 前往团队管理界面 \u003e 账单，你将不会再看到任何有关 到期 相关的字样。 1Password Team 的所有者看不到其他用户的私有数据，但是可以在 Shared 共享保险箱中与他人共享项目，除此之外与 1Password 个人版并无太大差异。 但是你需要注意: 该会员资格不得被转让或出售，因此这个 1Password for Teams 的所有者只能是你；另外，如果你的开源项目不再活跃，1Password 可能会收回你的会员资格。 ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:4:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Guides"],"content":"1Password 好处都有什么? 支持 macOS, iOS, Windows, Android, Linux, 浏览器插件和命令行 可以生成 SSH Key 公私钥，并使用 1Password-CLI 将其用于 Git Commit 签名或其他自动化 Workflow 调用 1Password-CLI 或者电脑唤醒后可以通过 Windows Hello / Touch ID / Face ID 快速鉴权 (可能之后会支持 Vision Pro 的 Optic ID)，不过电脑重启后或长时间未登录需要强制手动输入主密码 相比于每个网站都使用类似的密码，使用 1Password 可以让你为每个网站都生成不同的密码，以防撞库导致其他网站密码同样泄露 相比在浏览器中保存密码，1Password 可以 减少 因计算机被 Malware 潜入而导致账户密码被盗的情况 自建 Bitwarden Self Host 是一个不错的低成本方案，但是其存在诸多不稳定因素，一旦服务器宕机数据便无法访问。我个人认为 1Password 团队还是比我的运维技术更强的。🙃 其余的可能就需要你探索了… ","date":"2025-03-14","objectID":"/applying-1password-open-source-plan/:5:0","tags":["Apply","1Password","OpenSource"],"title":"通过开源项目申请 1Password OpenSource 以获得 Teams 订阅许可证","uri":"/applying-1password-open-source-plan/"},{"categories":["Build"],"content":"安装环境依赖 brew install automake autoconf libtool pkg-config texinfo coreutils gnu-getopt \\ python@3 cmake ninja ccache bison byacc gettext wget pcre maven llvm@16 openjdk@17 npmDoris master 目前只支持 jdk17 版本 需要设置的环境变量 export JAVA_HOME=\"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\" export PATH=$JAVA_HOME/bin:$PATH export PATH=\"/opt/homebrew/opt/openjdk@17/bin:$PATH\" export PATH=\"/opt/homebrew/opt/texinfo/bin:$PATH\"","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:1:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"拉取自己的代码 拉取代码 cd ~ mkdir DorisDev cd DorisDev git clone https://github.com/GitHubID/doris.git 设置环境变量 export DORIS_HOME=~/DorisDev/doris export PATH=$DORIS_HOME/bin:$PATH ","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:2:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"下载 Doris 编译依赖 Apache Doris Third Party Prebuilt页面有所有第三方库的源码，可以直接下载doris-thirdparty-source.tgz获得。 可以在Apache Doris Third Party Prebuilt页面直接下载预编译好的第三方库，省去编译第三方库的过程，参考下面的命令。 cd thirdparty rm -rf installed # Intel 芯片 curl -L https://github.com/apache/doris-thirdparty/releases/download/automation/doris-thirdparty-prebuilt-darwin-x86_64.tar.xz \\ -o - | tar -Jxf - # Apple Silicon 芯片 curl -L https://github.com/apache/doris-thirdparty/releases/download/automation/doris-thirdparty-prebuilt-darwin-arm64.tar.xz \\ -o - | tar -Jxf - # 保证 protoc 和 thrift 能够正常运行 cd installed/bin ./protoc --version ./thrift --version 运行protoc和thrift的时候可能会遇到无法打开，因为无法验证开发者的问题，可以到前往安全性与隐私。点按通用面板中的仍要打开按钮，以确认打算打开该二进制。参考https://support.apple.com/zh-cn/HT202491。 ","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:3:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"修改系统最大文件句柄数 # bash echo 'ulimit -n 65536' \u003e\u003e~/.bashrc # zsh echo 'ulimit -n 65536' \u003e\u003e~/.zshrc","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:4:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"编译 Doris cd $DORIS_HOME sh build.sh","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:5:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"编译过程中可能会遇到高版本的 Node.js 导致的错误 M1 目前没遇到过。 opensslErrorStack: [’error:03000086:digital envelope routines::initialization error’] library: ‘digital envelope routines’ reason: ‘unsupported’ code: ‘ERR_OSSL_EVP_UNSUPPORTED’ 以下命令解决问题。参考https://stackoverflow.com/questions/74726224/opensslerrorstack-error03000086digital-envelope-routinesinitialization-e #指示Node.js使用旧版的OpenSSL提供程序 export NODE_OPTIONS=--openssl-legacy-provider","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:6:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"编译过程中可能会遇到 jni.h not found Mac 的 JDK 在更深一层目录。 export JAVA_HOME=\"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\" export PATH=$JAVA_HOME/bin:$PATH","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:7:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"配置 Debug 环境 # 将编译好的包cp出来 cp -r output ../doris-run # 配置FE/BE的conf，用默认的也行吧 1、IP、目录 2、BE 额外配置 min_file_descriptor_number = 10000","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:8:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":["Build"],"content":"开始用 IDE 进行 Debug 参考官方OK CLion Mac 调试 BE IntelliJ IDEA Mac 调试 FE ","date":"2025-03-09","objectID":"/build-doris-on-macbook-m1/:9:0","tags":["Doris","MacBook","M1"],"title":"Build Doris on MacBook M1","uri":"/build-doris-on-macbook-m1/"},{"categories":null,"content":"关于 LoveIt","date":"2019-08-02","objectID":"/about/","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"  LoveIt 是一个由  Dillon 开发的简洁、优雅且高效的 Hugo 博客主题。 它的原型基于 LeaveIt 主题 和 KeepIt 主题。 Hugo 主题 LoveIt ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特性 ","date":"2019-08-02","objectID":"/about/:1:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"性能和 SEO  性能优化：在 Google PageSpeed Insights 中， 99/100 的移动设备得分和 100/100 的桌面设备得分  使用基于 JSON-LD 格式 的 SEO SCHEMA 文件进行 SEO 优化  支持 Google Analytics  支持 Fathom Analytics  支持 Plausible Analytics  支持 Yandex Metrica  支持搜索引擎的网站验证 (Google, Bind, Yandex 和 Baidu)  支持所有第三方库的 CDN  基于 lazysizes 自动转换图片为懒加载 ","date":"2019-08-02","objectID":"/about/:1:1","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"外观和布局  桌面端/移动端 响应式布局  浅色/深色 主题模式  全局一致的设计语言  支持分页  易用和自动展开的文章目录  支持多语言和国际化  美观的 CSS 动画 社交和评论系统  支持 Gravatar 头像  支持本地头像  支持多达 76 种社交链接  支持多达 24 种网站分享  支持 Disqus 评论系统  支持 Gitalk 评论系统  支持 Valine 评论系统  支持 Facebook comments 评论系统  支持 Telegram comments 评论系统  支持 Commento 评论系统  支持 utterances 评论系统  支持 giscus 评论系统 ","date":"2019-08-02","objectID":"/about/:1:2","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"扩展功能  支持基于 Lunr.js 或 algolia 的搜索  支持 Twemoji  支持代码高亮  一键复制代码到剪贴板  支持基于 lightGallery 的图片画廊  支持 Font Awesome 图标的扩展 Markdown 语法  支持上标注释的扩展 Markdown 语法  支持分数的扩展 Markdown 语法  支持基于 $\\KaTeX$ 的数学公式  支持基于 mermaid 的图表 shortcode  支持基于 ECharts 的交互式数据可视化 shortcode  支持基于 Mapbox GL JS 的 Mapbox shortcode  支持基于 APlayer 和 MetingJS 的音乐播放器 shortcode  支持 Bilibili 视频 shortcode  支持多种注释的 shortcode  支持自定义样式的 shortcode  支持自定义脚本的 shortcode  支持基于 TypeIt 的打字动画 shortcode  支持基于 cookieconsent 的 Cookie 许可横幅  支持人物标签的 shortcode … ","date":"2019-08-02","objectID":"/about/:1:3","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"许可协议 LoveIt 根据 MIT 许可协议授权。 更多信息请查看 LICENSE 文件。 ","date":"2019-08-02","objectID":"/about/:2:0","tags":null,"title":"关于 LoveIt","uri":"/about/"},{"categories":null,"content":"特别感谢 LoveIt 主题中用到了以下项目，感谢它们的作者： modern-normalize Font Awesome Simple Icons Animate.css autocomplete Lunr.js algoliasearch lazysizes object-fit-images Twemoji emoji-data lightGallery clipboard.js Sharer.js TypeIt $\\KaTeX$ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:3:0","tags":null,"title":"关于 LoveIt","uri":"/about/"}]