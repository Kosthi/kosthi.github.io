<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Performance Optimization on LoveIt</title><link>https://koschei.top/en/tags/performance-optimization/</link><description>Recent content in Performance Optimization on LoveIt</description><generator>Hugo</generator><language>en</language><managingEditor>nitianzero@gmail.com (Koschei)</managingEditor><webMaster>nitianzero@gmail.com (Koschei)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 30 Jan 2026 02:27:52 +0800</lastBuildDate><atom:link href="https://koschei.top/en/tags/performance-optimization/index.xml" rel="self" type="application/rss+xml"/><item><title>High-Performance BPE Tokenizer Optimization: From 10 Minutes to 1 Second</title><link>https://koschei.top/en/bpe-optimization/</link><pubDate>Sat, 14 Jun 2025 17:43:58 +0800</pubDate><author>nitianzero@gmail.com (Koschei)</author><guid>https://koschei.top/en/bpe-optimization/</guid><description>&lt;blockquote&gt;
&lt;p&gt;This article is supplementary reading for &lt;a href="https://koschei.top/posts/cs336-assign1/" rel=""&gt;CS336 Assignment 1&lt;/a&gt;, providing a detailed introduction to the optimized implementation of the BPE tokenizer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;The recommended cppyy in the documentation has issues in Mac and Linux environments. To pursue high performance, I used Pybind11 to bind C++ code: pre-tokenization is handled by Python, while the BPE merge process is delegated to C++. The actual biggest bottleneck is still pre-tokenization, which can be parallelized using the existing code &lt;code&gt;pretokenization_example.py&lt;/code&gt; for chunked parallel processing (8 cores 100s â†’ 16 cores 30s).&lt;/p&gt;</description></item></channel></rss>